{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network Incremental.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzJdVDEVwLfvPoxA3ZqbZ4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMDohLmFbF1H"
      },
      "source": [
        "## MLPRegressor Batch és Online\n",
        "\n",
        "Különböző beállításokkal,\n",
        "\n",
        "Baromira nem mindegy, hogy milyen beállításokat használunk, néha ezek hatására képtelen tanulni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZttEkvWBlNx"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--9yZpGWJfCK"
      },
      "source": [
        "x = np.arange(0, 600, 1)\n",
        "\n",
        "y = np.sin(x/180) + np.sin(x/60)\n",
        "\n",
        "x = x.reshape(-1,1)\n",
        "y = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyN_wDtWgTKt"
      },
      "source": [
        "## Tanh (logistic, relu)\n",
        "\n",
        "## SGD (adam)\n",
        "\n",
        "## Warm_start (False, True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZgP8apKYEv8"
      },
      "source": [
        "mlp = MLPRegressor(hidden_layer_sizes=(3, ),\n",
        "                   activation='tanh', \n",
        "                   solver='sgd',\n",
        "                   batch_size='auto',\n",
        "                   learning_rate_init=0.01,\n",
        "                   max_iter=2000,\n",
        "                   shuffle=False,\n",
        "                   random_state=1,\n",
        "                   momentum=0.9,\n",
        "                   nesterovs_momentum=True,\n",
        "                   early_stopping=True,\n",
        "                   n_iter_no_change=2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXXezdwGehQD"
      },
      "source": [
        "## Ilyen az amikor x és y is (-1,1) közé van normalizálva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnNyaX5nfx4G"
      },
      "source": [
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_x_one.fit(x)\n",
        "xs1 = scaler_x_one.transform(x)\n",
        "print('xs1.min = ', xs1.min())\n",
        "print('xs1.max = ', xs1.max())\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one.fit(y.reshape(-1,1))\n",
        "ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "print('ys1.min = ', ys1.min())\n",
        "print('ys1.max = ', ys1.max())\n",
        "print('ys1.shape = ', ys1.shape)\n",
        "x_scaled = xs1\n",
        "y_scaled = ys1\n",
        "mlp.fit(x_scaled, y_scaled)\n",
        "predicted = mlp.predict(x_scaled)\n",
        "plt.scatter(x_scaled, y_scaled)\n",
        "plt.plot(x_scaled, predicted, c='black')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YrMrTPajHoL"
      },
      "source": [
        "## Tehát a fentiekből az látszik\n",
        "\n",
        "#### Hogy a 'logistic' esetében nem képes megtalálni a megfelelő összefüggést.\n",
        "\n",
        "Azonban alább elvégeztem a következő kísérletet és az derült ki,<br>\n",
        "hogy az 'sgd' optimizer nem volt képes megtalálni az összefüggést.<br>\n",
        "Ha az optimizer 'adam' akkor a ha mindkét változót (-1,1) tartományba<br>\n",
        "normalizálom, akkor szintén jó megoldás születik.\n",
        "\n",
        "Ebből azt a következtetést vonom le, hogy 'logistic' esetén is az a célravezető<br>\n",
        "ha mindkét válotzót a (-1,1) tartományba transzformálom."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGGiJ9W2zWXm"
      },
      "source": [
        "## Bemutató"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhQFTQB5hQmE"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_x_one.fit(x)\n",
        "xs1 = scaler_x_one.transform(x)\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one.fit(y.reshape(-1,1))\n",
        "ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "print('xs1.min = ', xs1.min())\n",
        "print('xs1.max = ', xs1.max())\n",
        "print('ys1.min = ', ys1.min())\n",
        "print('ys1.max = ', ys1.max())\n",
        "print('ys1.shape = ', ys1.shape)\n",
        "x_scaled = xs1\n",
        "y_scaled = ys1\n",
        "\n",
        "\n",
        "for i in range(0, 1000, 50):\n",
        "  print('#i = ', i)\n",
        "  if( i != 0 ):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                      activation='tanh', \n",
        "                      solver='sgd',\n",
        "                      batch_size='auto',\n",
        "                      learning_rate_init=0.01,\n",
        "                      max_iter=i,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      n_iter_no_change=2000)\n",
        "\n",
        "    mlp.fit(x_scaled, y_scaled)\n",
        "    predicted = mlp.predict(x_scaled)\n",
        "    plt.scatter(x_scaled, y_scaled)\n",
        "    plt.plot(x_scaled, predicted, c='black')\n",
        "    plt.title('#i = {0:03}'.format(i))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u6FW8AzBRpu"
      },
      "source": [
        "## Ez így rossz Warm_start (False, True)\n",
        "\n",
        "Mert a for cikluson belül példányosítom az ``` MLPRegressor ``` ezért nem is működik.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHEjvmpN3I7N"
      },
      "source": [
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_x_one.fit(x)\n",
        "xs1 = scaler_x_one.transform(x)\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one.fit(y.reshape(-1,1))\n",
        "ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "print('xs1.min = ', xs1.min())\n",
        "print('xs1.max = ', xs1.max())\n",
        "print('ys1.min = ', ys1.min())\n",
        "print('ys1.max = ', ys1.max())\n",
        "print('ys1.shape = ', ys1.shape)\n",
        "x_scaled = xs1\n",
        "y_scaled = ys1\n",
        "\n",
        "\n",
        "for i in range(0, 600, 100):\n",
        "  print('#i = ', i)\n",
        "  if( i != 0 ):\n",
        "    mlp1 = MLPRegressor(hidden_layer_sizes=(3, ),\n",
        "                      activation='tanh', \n",
        "                      solver='sgd',\n",
        "                      batch_size='auto',\n",
        "                      learning_rate_init=0.05,\n",
        "                      max_iter=i,\n",
        "                      shuffle=False,\n",
        "                      random_state=1,\n",
        "                      warm_start=False,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      n_iter_no_change=2000)\n",
        "    \n",
        "    mlp2 = MLPRegressor(hidden_layer_sizes=(3, ),\n",
        "                      activation='tanh', \n",
        "                      solver='sgd',\n",
        "                      batch_size='auto',\n",
        "                      learning_rate_init=0.05,\n",
        "                      max_iter=i,\n",
        "                      shuffle=False,\n",
        "                      random_state=1,\n",
        "                      warm_start=True,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      n_iter_no_change=2000)\n",
        "\n",
        "    mlp1.fit(x_scaled, y_scaled)\n",
        "    predicted1 = mlp1.predict(x_scaled)\n",
        "\n",
        "    mlp2.fit(x_scaled, y_scaled)\n",
        "    predicted2 = mlp2.predict(x_scaled)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted1, c='black')\n",
        "    ax[1].scatter(x_scaled, y_scaled)\n",
        "    ax[1].plot(x_scaled, predicted2, c='black')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np3dEOLjGD3X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeLTiHvxGHlS"
      },
      "source": [
        "## Ez így jó Warm_start (False, True)\n",
        "\n",
        "Mert a for cikluson kívűl példányosítom az ``` MLPRegressor ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3dJTERMGDxw"
      },
      "source": [
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_x_one.fit(x)\n",
        "xs1 = scaler_x_one.transform(x)\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one.fit(y.reshape(-1,1))\n",
        "ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "print('xs1.min = ', xs1.min())\n",
        "print('xs1.max = ', xs1.max())\n",
        "print('ys1.min = ', ys1.min())\n",
        "print('ys1.max = ', ys1.max())\n",
        "print('ys1.shape = ', ys1.shape)\n",
        "x_scaled = xs1\n",
        "y_scaled = ys1\n",
        "\n",
        "mlp1 = MLPRegressor(hidden_layer_sizes=(3, ),\n",
        "                  activation='tanh', \n",
        "                  solver='sgd',\n",
        "                  batch_size='auto',\n",
        "                  learning_rate_init=0.05,\n",
        "                  max_iter=i,\n",
        "                  shuffle=False,\n",
        "                  random_state=1,\n",
        "                  warm_start=False,\n",
        "                  momentum=0.9,\n",
        "                  nesterovs_momentum=True,\n",
        "                  early_stopping=True,\n",
        "                  n_iter_no_change=2000)\n",
        "\n",
        "mlp2 = MLPRegressor(hidden_layer_sizes=(3, ),\n",
        "                  activation='tanh', \n",
        "                  solver='sgd',\n",
        "                  batch_size='auto',\n",
        "                  learning_rate_init=0.05,\n",
        "                  max_iter=i,\n",
        "                  shuffle=False,\n",
        "                  random_state=1,\n",
        "                  warm_start=True,\n",
        "                  momentum=0.9,\n",
        "                  nesterovs_momentum=True,\n",
        "                  early_stopping=True,\n",
        "                  n_iter_no_change=2000)\n",
        "\n",
        "for i in range(0, 600, 100):\n",
        "  print('#i = ', i)\n",
        "  if( i != 0 ):\n",
        "\n",
        "    mlp1.fit(x_scaled, y_scaled)\n",
        "    predicted1 = mlp1.predict(x_scaled)\n",
        "\n",
        "    mlp2.fit(x_scaled, y_scaled)\n",
        "    predicted2 = mlp2.predict(x_scaled)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted1, c='black')\n",
        "    ax[1].scatter(x_scaled, y_scaled)\n",
        "    ax[1].plot(x_scaled, predicted2, c='black')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVQQHw7N3Wau"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-oc01LzC_xI"
      },
      "source": [
        "## Online learning\n",
        "\n",
        "## Kívül van normálva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2OFwmuIR5rx"
      },
      "source": [
        "mlp.best_loss_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7nfiBh2R6Ji"
      },
      "source": [
        "mlp.loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PG08LuLSKKc"
      },
      "source": [
        "mlp.loss_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RULrotXSKGw"
      },
      "source": [
        "mlp.loss_curve_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVi8gYMISRUf"
      },
      "source": [
        "mlp.partial_fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E_uJZKaSl0m"
      },
      "source": [
        "plt.plot(mlp.loss_curve_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CQCnxXjR-Dv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hXI9qp-R-Sb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyfTcaCGoJ_1"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "\n",
        "# mindíg az aktuális értéket normáljuk és nem előre\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "################################################################################\n",
        "# A lényeg, hogy nehogy  a forciklusba tegyük a példányosítást, mert akkor\n",
        "# minden egyes alkalommal újra új példány jön létre és elfelejti a korábbi\n",
        "# súllyokat amiket megtanult\n",
        "################################################################################\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                  activation='tanh',              # tanh, logistic, relu\n",
        "                  solver='sgd',                   # adam, sgd, lbfgs\n",
        "                  batch_size='auto',\n",
        "                  learning_rate_init=0.1,         # Fontos 0.01, 0.02, 0.05, 0.1\n",
        "                  max_iter=1,                     # Fontos\n",
        "                  shuffle=False,                  # Fontos\n",
        "                  random_state=1,\n",
        "                  warm_start=True,                # Fontos ?\n",
        "                  momentum=0.9,\n",
        "                  nesterovs_momentum=False,\n",
        "                  early_stopping=False,           # Fontos ?\n",
        "                  verbose=1,\n",
        "                  n_iter_no_change=1000)\n",
        "\n",
        "\n",
        "for i in range(0, 500, 1):\n",
        "  print('#i = ', i)\n",
        "  if( i > 2 ):\n",
        "\n",
        "    scaler_x_one.fit(x)\n",
        "    scaler_y_one.fit(y.reshape(-1,1))\n",
        "    xs1 = scaler_x_one.transform(x)\n",
        "    ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "    print('xs1.min = ', xs1.min())\n",
        "    print('xs1.max = ', xs1.max())\n",
        "    print('ys1.min = ', ys1.min())\n",
        "    print('ys1.max = ', ys1.max())\n",
        "    print('ys1.shape = ', ys1.shape)\n",
        "    x_scaled = xs1\n",
        "    y_scaled = ys1\n",
        "\n",
        "    x_part = x_scaled[:i,:]\n",
        "    y_part = y_scaled[:i,:]\n",
        "\n",
        "    mlp.fit(x_part, y_part)\n",
        "    predicted = mlp.predict(x_part)\n",
        "    plt.scatter(x_part, y_part)\n",
        "    plt.plot(x_part, predicted, c='black')\n",
        "    plt.title('#i = ' + str(i) + ' r2 = {:.3f}'.format(round(r2,3)) + ' loss = {:.3f}'.format(round(mlp.loss_, 3)))\n",
        "    plt.ylim((-1.2, 1.2))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T44x_ZH6KYi"
      },
      "source": [
        "## Ugyan ez csak az illeszkedés mértékét is plottolja\n",
        "\n",
        "## Kívül van normálva\n",
        "\n",
        "Ami itt érdekes lehet, mi van ha nem egyesévél léptetem a for ciklust, az adatokat? (1, 2, 5, 10)\n",
        "\n",
        "### ToDo:\n",
        "\n",
        "Kipróbálni a  ```partial_fit``` methodust a ```fit``` helyett.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8NgphYa6I5i"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "\n",
        "# mindíg az aktuális értéket normáljuk és nem előre\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "################################################################################\n",
        "# A lényeg, hogy nehogy  a forciklusba tegyük a példányosítást, mert akkor\n",
        "# minden egyes alkalommal újra új példány jön létre és elfelejti a korábbi\n",
        "# súllyokat amiket megtanult\n",
        "################################################################################\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                  activation='tanh',              # tanh, logistic, relu\n",
        "                  solver='sgd',                   # adam, sgd, lbfgs\n",
        "                  batch_size='auto',\n",
        "                  learning_rate_init=0.1,         # Fontos 0.01, 0.02, 0.05, 0.1\n",
        "                  max_iter=1,                     # Fontos\n",
        "                  shuffle=False,                  # Fontos\n",
        "                  random_state=1,\n",
        "                  warm_start=True,                # Fontos ?\n",
        "                  momentum=0.9,\n",
        "                  nesterovs_momentum=False,\n",
        "                  early_stopping=False,           # Fontos ?\n",
        "                  verbose=1,\n",
        "                  n_iter_no_change=1000)\n",
        "\n",
        "r2_history = [0]\n",
        "\n",
        "for i in range(0, 500, 1):\n",
        "  print('#i = ', i)\n",
        "  if( i > 2 ):\n",
        "\n",
        "    scaler_x_one.fit(x)\n",
        "    scaler_y_one.fit(y.reshape(-1,1))\n",
        "    xs1 = scaler_x_one.transform(x)\n",
        "    ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "    print('xs1.min = ', xs1.min())\n",
        "    print('xs1.max = ', xs1.max())\n",
        "    print('ys1.min = ', ys1.min())\n",
        "    print('ys1.max = ', ys1.max())\n",
        "    print('ys1.shape = ', ys1.shape)\n",
        "    x_scaled = xs1\n",
        "    y_scaled = ys1\n",
        "\n",
        "    # faszomat bazmeg, megint kint van skálázva a kurva életbe !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    x_part = x_scaled[:i,:]\n",
        "    y_part = y_scaled[:i,:]\n",
        "\n",
        "    mlp.fit(x_part, y_part)\n",
        "    predicted = mlp.predict(x_part)\n",
        "\n",
        "    r2 = r2_score(y_part, predicted)\n",
        "    r2_history.append(r2)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,4), sharey=False)\n",
        "    ax[0].scatter(x_part, y_part)\n",
        "    ax[0].plot(x_part, predicted, c='red')\n",
        "    ax[0].set_ylim((-1.2, 1.2))\n",
        "    ax[0].set_title('#i = ' + str(i) + ' r2 = {:.3f}'.format(round(r2,3)) + ' loss = {:.3f}'.format(round(mlp.loss_, 3)))\n",
        "    ax[1].plot(r2_history, c='black')\n",
        "    ax[1].set_title('r2 = {:.3f}'.format(round(r2,3)))\n",
        "    ax[1].set_ylim((0, 1.1))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riQ_a_4mcoFZ"
      },
      "source": [
        "## Ugyan ez csak az illeszkedés mértékét is plottolja\n",
        "\n",
        "## Belül van normálva\n",
        "\n",
        "Ami itt érdekes lehet, mi van ha nem egyesévél léptetem a for ciklust, az adatokat? (1, 2, 5, 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTvso4a2b9Oz"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "\n",
        "# mindíg az aktuális értéket normáljuk és nem előre\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "################################################################################\n",
        "# A lényeg, hogy nehogy  a forciklusba tegyük a példányosítást, mert akkor\n",
        "# minden egyes alkalommal újra új példány jön létre és elfelejti a korábbi\n",
        "# súllyokat amiket megtanult\n",
        "################################################################################\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                  activation='tanh',              # tanh, logistic, relu\n",
        "                  solver='sgd',                   # adam, sgd, lbfgs\n",
        "                  batch_size='auto',\n",
        "                  learning_rate_init=0.1,         # Fontos 0.01, 0.02, 0.05, 0.1\n",
        "                  max_iter=1,                     # Fontos\n",
        "                  shuffle=False,                  # Fontos\n",
        "                  random_state=1,\n",
        "                  warm_start=True,                # Fontos ?\n",
        "                  momentum=0.9,\n",
        "                  nesterovs_momentum=False,\n",
        "                  early_stopping=False,           # Fontos ?\n",
        "                  verbose=1,\n",
        "                  n_iter_no_change=1000)\n",
        "\n",
        "r2_history = [0]\n",
        "\n",
        "for i in range(0, 500, 1):\n",
        "  print('#i = ', i)\n",
        "  if( i > 2 ):\n",
        "\n",
        "    # faszomat bazmeg, na most már bent van skálázva !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "\n",
        "    x_part = x[:i,:]\n",
        "    y_part = y[:i]\n",
        "\n",
        "    scaler_x_one.fit(x_part)\n",
        "    scaler_y_one.fit(y_part.reshape(-1,1))\n",
        "    xs1 = scaler_x_one.transform(x_part)\n",
        "    ys1 = scaler_y_one.transform(y_part.reshape(-1,1))\n",
        "    print('xs1.min = ', xs1.min())\n",
        "    print('xs1.max = ', xs1.max())\n",
        "    print('ys1.min = ', ys1.min())\n",
        "    print('ys1.max = ', ys1.max())\n",
        "    print('ys1.shape = ', ys1.shape)\n",
        "    x_scaled = xs1\n",
        "    y_scaled = ys1\n",
        "\n",
        "\n",
        "    mlp.fit(x_scaled, y_scaled)\n",
        "    predicted = mlp.predict(x_scaled)\n",
        "\n",
        "    r2 = r2_score(y_scaled, predicted)\n",
        "    r2_history.append(r2)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,4), sharey=False)\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted, c='red')\n",
        "    ax[0].set_ylim((-1.2, 1.2))\n",
        "    ax[0].set_title('#i = ' + str(i) + ' r2 = {:.3f}'.format(round(r2,3)) + ' loss = {:.3f}'.format(round(mlp.loss_, 3)))\n",
        "    ax[1].plot(r2_history, c='black')\n",
        "    ax[1].set_title('r2 = {:.3f}'.format(round(r2,3)))\n",
        "    ax[1].set_ylim((0, 1.1))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrJ10IVfb9Gk"
      },
      "source": [
        "plt.plot(mlp.loss_curve_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IASCtcy1TIMm"
      },
      "source": [
        "## Van egy úgynevezett zseniális ötletem\n",
        "\n",
        "Az merült ma fel bennem, hogy mi lenne akkor ha online módszerrel folyamatosan<br>\n",
        "tanítanánk a neurális hálót, de nem csak egyet, hanem rögtön többet is<br>\n",
        "különböző learning rate-tel.<br>\n",
        "\n",
        "Ennek az a lényege, hogy a tanulás egyes pontjain a magasabb learning rate<br>\n",
        "miatt néha 'ugrik' egyet a becslés az egyel korábbihoz képest és lehet,<br>\n",
        "hogy egy másik learning rate-tel tanított háló 'abszolút hibája' vagy<br>\n",
        "'négyzetes hibája' alapján közelebb áll a becslése a valós értékehez<br>\n",
        "ezért mindíg azt választjuk ki egy adott időpontban amelyik becslése<br>\n",
        "pontosabb eredményt ad.<br>\n",
        "\n",
        "Ilyen módon a 'hiper paramétert' is menet közben választjuk ki<br>\n",
        "\n",
        "Van ennek egyébként egy tágabbb elméleti megfontolása is<br>\n",
        "\n",
        "Mivel incrementált vagyis online tanításról van szó mehet közben<br>\n",
        "meggondolhatjuk magunkat és fenn áll annak a lehetősége, hogy<br>\n",
        "másik hiperparaméterrel kellett volna tanítani a hálót.<br>\n",
        "Csakhogy ezen menet közben már nem lehet változtatni ezért azt csinálom<br>\n",
        "hogy egyszerre több neurális hálót kezdek el tanítani különböző<br>\n",
        "hiperparaméterekkel és mindíg azt választom amelyik jobb becslést ad.<br>\n",
        "\n",
        "Egy picit olyan post-hoc hipotézis vizsgálathoz hasonlít ez mint, ha<br>\n",
        "azt mondom, hogy az volt a feltételezésem, hogy de kiderült, hogy.<br>\n",
        "\n",
        "Tehát élünk annak a lehetőségével, hogy módosítsunk egy korábbi feltételezésünkön<br>\n",
        "ami még mindíg jobb mintha ragaszkodnánk ahhoz, amiről már tudjuk, hogy rossz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUT2C98GCGd-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsTiTvnuCGbI"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "\n",
        "# mindíg az aktuális értéket normáljuk és nem előre\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "################################################################################\n",
        "# A lényeg, hogy nehogy  a forciklusba tegyük a példányosítást, mert akkor\n",
        "# minden egyes alkalommal újra új példány jön létre és elfelejti a korábbi\n",
        "# súllyokat amiket megtanult\n",
        "################################################################################\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                  activation='tanh',              # tanh, logistic, relu\n",
        "                  solver='sgd',                   # adam, sgd, lbfgs\n",
        "                  batch_size='auto',\n",
        "                  learning_rate_init=0.1,         # Fontos 0.01, 0.02, 0.05, 0.1\n",
        "                  max_iter=1,                     # Fontos\n",
        "                  shuffle=False,                  # Fontos\n",
        "                  random_state=1,\n",
        "                  warm_start=True,                # Fontos ?\n",
        "                  momentum=0.9,\n",
        "                  nesterovs_momentum=False,\n",
        "                  early_stopping=False,           # Fontos ?\n",
        "                  verbose=1,\n",
        "                  n_iter_no_change=1000)\n",
        "\n",
        "r2_history = [0]\n",
        "\n",
        "for i in range(0, 500, 1):\n",
        "  print('#i = ', i)\n",
        "  if( i > 2 ):\n",
        "\n",
        "    x_part = x[:i,:]\n",
        "    y_part = y[:i]\n",
        "\n",
        "    scaler_x_one.fit(x_part)\n",
        "    scaler_y_one.fit(y_part.reshape(-1,1))\n",
        "    xs1 = scaler_x_one.transform(x_part)\n",
        "    ys1 = scaler_y_one.transform(y_part.reshape(-1,1))\n",
        "    x_scaled = xs1\n",
        "    y_scaled = ys1\n",
        "\n",
        "    x_scaled = scaler_x_one.fit_transform(x_part)\n",
        "    y_scaled = scaler_y_one.fit_transform(y_part.reshape(-1,1)).reshape(-1,1)\n",
        "\n",
        "\n",
        "\n",
        "    mlp.fit(x_scaled, y_scaled)\n",
        "    predicted = mlp.predict(x_scaled)\n",
        "\n",
        "    r2 = r2_score(y_scaled, predicted)\n",
        "    r2_history.append(r2)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,4), sharey=False)\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted, c='red')\n",
        "    ax[0].set_ylim((-1.2, 1.2))\n",
        "    ax[0].set_title('#i = ' + str(i) + ' r2 = {:.3f}'.format(round(r2,3)) + ' loss = {:.3f}'.format(round(mlp.loss_, 3)))\n",
        "    ax[1].plot(r2_history, c='black')\n",
        "    ax[1].set_title('r2 = {:.3f}'.format(round(r2,3)))\n",
        "    ax[1].set_ylim((0, 1.1))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2a6tEi-CGX6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxSgvYA1a_y"
      },
      "source": [
        "## ToDo\n",
        "\n",
        "Két dolgot kéne itt kipróbálni\n",
        "\n",
        "(A) az MLPRegressorn belül az iterációk számál lehet játszani\n",
        "\n",
        "(B) a for ciklus lépésközeivel lehet játszani\n",
        "\n",
        "\n",
        "(C) természetesen a learning ratetel is lehet játszani\n",
        "\n",
        "\n",
        "(D) és a zseniális ötletemet sem szabad elvetni, hogy egyszerre több modelt tanítunk és minden egyes lépésben azt választjuk amelyik a legjobb eredményt adja éppen akkor\n",
        "\n",
        "(E) ki szeretném próbálni azt is, hogy a partial_fit metodust hívom úgy, hogy\n",
        "az összes adatot odaadom neki, 1 iteráció van megengedve, de ezt meghívom 2000-szer és megnézem, hogy azonos eredményt adott-e mintha a sima fit() metodust hívom 2000 max_iter paraméterrel (természetesen a folyamatot is monitorozni kell és összehasonlítani)\n",
        "\n",
        "(F) !\n",
        "\n",
        "Illetve van még egy olyan kísérlet, hogy a partial_fit, vagy a fit() hívásakor csak az új adatot adom neki oda és nem a megnövelt adatot (!) van különgég. Az egyik esetben csak egy adatot kap, a második esetben mindig n + 1 adatot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmO_KWazz_YX"
      },
      "source": [
        "## ToDo (E)\n",
        "\n",
        "ki szeretném próbálni azt is, hogy a partial_fit metodust hívom úgy, hogy az összes adatot odaadom neki, 1 iteráció van megengedve, de ezt meghívom 2000-szer és megnézem, hogy azonos eredményt adott-e mintha a sima fit() metodust hívom 2000 max_iter paraméterrel (természetesen a folyamatot is monitorozni kell és összehasonlítani)\n",
        "\n",
        "Tehát a lényeg, hogy\n",
        "- mindíg megkapja az összes adatot\n",
        "- de egyszerre csak egy iterációt csinál\n",
        "- viszont ezt úgy, hogy nem felejt -> incremental learning\n",
        "- végül összehasonlítaom azzal, ha a max_iter = 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU9Q-L7VCGUj"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "# Mivel minden adatot odadunk ezért egy lépésben normalizálhatjuk az egészet\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "x_scaled = scaler_x_one.fit_transform(x)\n",
        "y_scaled = scaler_y_one.fit_transform(y.reshape(-1,1)).reshape(-1,1)\n",
        "\n",
        "print('x_scaled.shape = ', x_scaled.shape)\n",
        "print('y_scaled.shape = ', y_scaled.shape)\n",
        "print('x_scaled.min   = ', x_scaled.min())\n",
        "print('x_scaled.max   = ', x_scaled.max())\n",
        "print('y_scaled.min   = ', y_scaled.min())\n",
        "print('y_scaled.max   = ', y_scaled.max())\n",
        "\n",
        "################################################################################\n",
        "# A lényeg, hogy nehogy  a forciklusba tegyük a példányosítást, mert akkor\n",
        "# minden egyes alkalommal újra új példány jön létre és elfelejti a korábbi\n",
        "# súllyokat amiket megtanult\n",
        "################################################################################\n",
        "\n",
        "mlp_online = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                          activation='tanh',              # tanh, logistic, relu\n",
        "                          solver='sgd',                   # adam, sgd, lbfgs\n",
        "                          batch_size='auto',\n",
        "                          learning_rate_init=0.1,         # Fontos 0.01, 0.02, 0.05, 0.1\n",
        "                          max_iter=1,                     # Mindíg csak egy iterációt végzünk el\n",
        "                          shuffle=False,                  # Fontos\n",
        "                          random_state=1,\n",
        "                          warm_start=True,                # Fontos\n",
        "                          momentum=0.9,\n",
        "                          nesterovs_momentum=False,\n",
        "                          early_stopping=False,           # Fontos\n",
        "                          verbose=0,\n",
        "                          n_iter_no_change=1000)\n",
        "\n",
        "r2_online_history = [0]\n",
        "\n",
        "for i in range(0, 1000, 1):\n",
        "  # print('#i = ', i)\n",
        "\n",
        "  mlp_online.fit(x_scaled, y_scaled)\n",
        "  predicted_online = mlp_online.predict(x_scaled)\n",
        "\n",
        "  r2_online = r2_score(y_scaled, predicted_online)\n",
        "  r2_online_history.append(r2_online)\n",
        "\n",
        "  error_online = mean_squared_error(y_scaled, predicted_online)\n",
        "\n",
        "  if( i % 10 == 0 and i > 0 ):\n",
        "\n",
        "    # Néhány lépésenként nézzük meg, hogy milyen eredményt ad neurális háló\n",
        "    # ha batchben tanítjuk. Ez a háló mindíg újra tanul, és max_iter = i\n",
        "    # számú lépést fog végrehajtani\n",
        "\n",
        "    mlp_batch  = MLPRegressor(hidden_layer_sizes=(10, 5),\n",
        "                              activation='tanh',              # tanh, logistic, relu\n",
        "                              solver='sgd',                   # adam, sgd, lbfgs\n",
        "                              batch_size='auto',\n",
        "                              learning_rate_init=0.1,         # Fontos 0.01, 0.02, 0.05, 0.1\n",
        "                              max_iter=i,                     # Az iterációk számát itt a for ciklusból kapjuk\n",
        "                              shuffle=False,                  # Fontos\n",
        "                              random_state=1,\n",
        "                              warm_start=False,               # Fontos\n",
        "                              momentum=0.9,\n",
        "                              nesterovs_momentum=False,\n",
        "                              early_stopping=False,\n",
        "                              verbose=0,\n",
        "                              n_iter_no_change=1000)\n",
        "    \n",
        "    mlp_batch.fit(x_scaled, y_scaled)\n",
        "    predicted_batch = mlp_batch.predict(x_scaled)\n",
        "\n",
        "    error_batch = mean_squared_error(y_scaled, predicted_batch)\n",
        "\n",
        "\n",
        "    # Plottoljuk ki az eredményeket\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,4), sharey=False)\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted_online, c='red', label='online error = ' + str(round(error_online, 3)))\n",
        "    ax[0].plot(x_scaled, predicted_batch, c='black', label='batch error  = ' + str(round(error_batch, 3)))\n",
        "    ax[0].set_ylim((-1.2, 1.2))\n",
        "    ax[0].set_title('#i = ' + str(i) + ' r2 = {:.3f}'.format(round(r2_online,3)) + ' loss = {:.3f}'.format(round(mlp_online.loss_, 3)))\n",
        "    ax[1].plot(r2_online_history, c='black')\n",
        "    ax[1].set_title('r2 = {:.3f}'.format(round(r2_online,3)))\n",
        "    ax[1].set_ylim((0, 1.1))\n",
        "    ax[0].legend(loc=3)\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Fűzzük össze a képeket\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AODrjsAVCGRH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug6rGuvrCGOD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KYARvP7CGLM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgoFBZYBCGIf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OskUc06rCGFe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB9HAvlZCGCa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8-326YzA2ZL"
      },
      "source": [
        "# Create images\n",
        "\n",
        "Ezt csak érdeksségnek raktam ide, kétféle képen ábrázolja a hiba (helyesebben) az r2 alakulását."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWNr19DWTPtz"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_x_one.fit(x)\n",
        "xs1 = scaler_x_one.transform(x)\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one.fit(y.reshape(-1,1))\n",
        "ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "print('xs1.min = ', xs1.min())\n",
        "print('xs1.max = ', xs1.max())\n",
        "print('ys1.min = ', ys1.min())\n",
        "print('ys1.max = ', ys1.max())\n",
        "print('ys1.shape = ', ys1.shape)\n",
        "x_scaled = xs1\n",
        "y_scaled = ys1\n",
        "\n",
        "r2_history = [0]\n",
        "\n",
        "for i in range(0, 150, 1):\n",
        "  print('#i = ', i)\n",
        "  if( i != 0 ):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=(30, 15),\n",
        "                      activation='tanh', \n",
        "                      solver='adam',\n",
        "                      batch_size='auto',\n",
        "                      learning_rate_init=0.01,\n",
        "                      max_iter=i,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      n_iter_no_change=2000)\n",
        "\n",
        "    mlp.fit(x_scaled, y_scaled)\n",
        "    predicted = mlp.predict(x_scaled)\n",
        "\n",
        "    r2 = r2_score(y_scaled, predicted)\n",
        "    r2_history.append(r2)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,4), sharey=False)\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted, c='red')\n",
        "    ax[0].set_ylim((-1.2, 1.2))\n",
        "    ax[0].set_title('#i = ' + str(i))\n",
        "    ax[1].plot(r2_history, c='black')\n",
        "    ax[1].set_title('r2 = {:.3f}'.format(round(r2,3)))\n",
        "    ax[1].set_ylim((0, 1.1))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP64Yo3kaVsy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq7kpBKf7m15"
      },
      "source": [
        "# Create images\n",
        "\n",
        "Ezt csak érdeksségnek raktam ide, kétféle képen ábrázolja az r2 alakulását futó ablakban."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "css56HHC_y4-"
      },
      "source": [
        "! rm *.png\n",
        "! rm *.gif\n",
        "\n",
        "scaler_x_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_x_one.fit(x)\n",
        "xs1 = scaler_x_one.transform(x)\n",
        "scaler_y_one = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y_one.fit(y.reshape(-1,1))\n",
        "ys1 = scaler_y_one.transform(y.reshape(-1,1))\n",
        "print('xs1.min = ', xs1.min())\n",
        "print('xs1.max = ', xs1.max())\n",
        "print('ys1.min = ', ys1.min())\n",
        "print('ys1.max = ', ys1.max())\n",
        "print('ys1.shape = ', ys1.shape)\n",
        "x_scaled = xs1\n",
        "y_scaled = ys1\n",
        "\n",
        "r2_history = [0]\n",
        "\n",
        "\n",
        "n = 150\n",
        "for i in range(0, n, 1):\n",
        "  print('#i = ', i)\n",
        "  if( i != 0 ):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=(30, 15),\n",
        "                      activation='tanh', \n",
        "                      solver='adam',\n",
        "                      batch_size='auto',\n",
        "                      learning_rate_init=0.01,\n",
        "                      max_iter=i,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=True,\n",
        "                      n_iter_no_change=2000)\n",
        "\n",
        "    mlp.fit(x_scaled, y_scaled)\n",
        "    predicted = mlp.predict(x_scaled)\n",
        "\n",
        "    r2 = r2_score(y_scaled, predicted)\n",
        "    r2_history.append(r2)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,4), sharey=False)\n",
        "    ax[0].scatter(x_scaled, y_scaled)\n",
        "    ax[0].plot(x_scaled, predicted, c='red')\n",
        "    ax[0].set_ylim((-1.2, 1.2))\n",
        "    ax[0].set_title('#i = ' + str(i))\n",
        "    ax[1].plot(r2_history, c='black')\n",
        "    ax[1].set_title('r2 = {:.3f}'.format(round(r2,3)))\n",
        "    ax[1].set_ylim((0, 1.1))\n",
        "    ax[1].set_xlim((0, n))\n",
        "    plt.savefig('image{0:03}'.format(i)+'.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "frames = []\n",
        "imgs = glob.glob(\"*.png\")\n",
        "imgs.sort()\n",
        "for i in imgs:\n",
        "    new_frame = Image.open(i)\n",
        "    frames.append(new_frame)\n",
        "\n",
        "frames[0].save('animation.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}