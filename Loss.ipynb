{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82614bb6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* Itt a fenti CSS j√∂het beillesztve */\n",
       "\n",
       "/* --- Alap st√≠lus --- */\n",
       "body, .rendered_html {\n",
       "    font-family: 'Segoe UI', 'Helvetica Neue', 'Helvetica', 'Arial', sans-serif;\n",
       "    // font-size: 16px;\n",
       "    font-size: 14px;\n",
       "    line-height: 1.6;\n",
       "    color: #1f1f1f;\n",
       "    // background-color: #f9f9f9;\n",
       "}\n",
       "\n",
       "/* --- C√≠msorok --- */\n",
       ".rendered_html h1 {\n",
       "    font-size: 2em;\n",
       "    border-bottom: 2px solid #ddd;\n",
       "    padding-bottom: 0.3em;\n",
       "    margin-top: 1.2em;\n",
       "}\n",
       ".rendered_html h2 {\n",
       "    font-size: 1.6em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       ".rendered_html h3 {\n",
       "    font-size: 1.3em;\n",
       "    margin-top: 0.8em;\n",
       "}\n",
       "\n",
       "/* --- K√≥dblokkok (Markdown output) --- */\n",
       ".rendered_html pre, .rendered_html code {\n",
       "    background: #2d2d2d;\n",
       "    color: #f8f8f2;\n",
       "    padding: 0.5em;\n",
       "    border-radius: 6px;\n",
       "    font-family: Consolas, 'Courier New', monospace;\n",
       "    font-size: 0.95em;\n",
       "}\n",
       "\n",
       "/* --- Inline code --- */\n",
       ".rendered_html code {\n",
       "    padding: 2px 6px;\n",
       "}\n",
       "\n",
       "/* --- List√°k --- */\n",
       ".rendered_html ul, .rendered_html ol {\n",
       "    padding-left: 2em;\n",
       "}\n",
       "\n",
       "/* --- T√°bl√°zatok --- */\n",
       ".rendered_html table {\n",
       "    border-collapse: collapse;\n",
       "    width: 100%;\n",
       "    margin: 1em 0;\n",
       "}\n",
       ".rendered_html th, .rendered_html td {\n",
       "    border: 1px solid #ccc;\n",
       "    padding: 8px;\n",
       "    text-align: left;\n",
       "}\n",
       ".rendered_html th {\n",
       "    background-color: #eee;\n",
       "}\n",
       "\n",
       "/* --- Kiemelt id√©zetek (blockquote) --- */\n",
       ".rendered_html blockquote {\n",
       "    border-left: 4px solid #ccc;\n",
       "    padding-left: 1em;\n",
       "    color: #666;\n",
       "    margin: 1em 0;\n",
       "}\n",
       "\n",
       "/* --- Linkek --- */\n",
       ".rendered_html a {\n",
       "    color: #2a7ae2;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".rendered_html a:hover {\n",
       "    text-decoration: underline;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat GPT css style\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<style>\n",
    "/* Itt a fenti CSS j√∂het beillesztve */\n",
    "\n",
    "/* --- Alap st√≠lus --- */\n",
    "body, .rendered_html {\n",
    "    font-family: 'Segoe UI', 'Helvetica Neue', 'Helvetica', 'Arial', sans-serif;\n",
    "    // font-size: 16px;\n",
    "    font-size: 14px;\n",
    "    line-height: 1.6;\n",
    "    color: #1f1f1f;\n",
    "    // background-color: #f9f9f9;\n",
    "}\n",
    "\n",
    "/* --- C√≠msorok --- */\n",
    ".rendered_html h1 {\n",
    "    font-size: 2em;\n",
    "    border-bottom: 2px solid #ddd;\n",
    "    padding-bottom: 0.3em;\n",
    "    margin-top: 1.2em;\n",
    "}\n",
    ".rendered_html h2 {\n",
    "    font-size: 1.6em;\n",
    "    margin-top: 1em;\n",
    "}\n",
    ".rendered_html h3 {\n",
    "    font-size: 1.3em;\n",
    "    margin-top: 0.8em;\n",
    "}\n",
    "\n",
    "/* --- K√≥dblokkok (Markdown output) --- */\n",
    ".rendered_html pre, .rendered_html code {\n",
    "    background: #2d2d2d;\n",
    "    color: #f8f8f2;\n",
    "    padding: 0.5em;\n",
    "    border-radius: 6px;\n",
    "    font-family: Consolas, 'Courier New', monospace;\n",
    "    font-size: 0.95em;\n",
    "}\n",
    "\n",
    "/* --- Inline code --- */\n",
    ".rendered_html code {\n",
    "    padding: 2px 6px;\n",
    "}\n",
    "\n",
    "/* --- List√°k --- */\n",
    ".rendered_html ul, .rendered_html ol {\n",
    "    padding-left: 2em;\n",
    "}\n",
    "\n",
    "/* --- T√°bl√°zatok --- */\n",
    ".rendered_html table {\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "    margin: 1em 0;\n",
    "}\n",
    ".rendered_html th, .rendered_html td {\n",
    "    border: 1px solid #ccc;\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "}\n",
    ".rendered_html th {\n",
    "    background-color: #eee;\n",
    "}\n",
    "\n",
    "/* --- Kiemelt id√©zetek (blockquote) --- */\n",
    ".rendered_html blockquote {\n",
    "    border-left: 4px solid #ccc;\n",
    "    padding-left: 1em;\n",
    "    color: #666;\n",
    "    margin: 1em 0;\n",
    "}\n",
    "\n",
    "/* --- Linkek --- */\n",
    ".rendered_html a {\n",
    "    color: #2a7ae2;\n",
    "    text-decoration: none;\n",
    "}\n",
    ".rendered_html a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    "\n",
    "</style>\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741dd0c3",
   "metadata": {},
   "source": [
    "<font color='red'>Chat GPT. Line√°ris regresszi√≥ eset√©ben √©rtem hogy mi a Mean Square Loss √©s azt is √©rtem, hogy ez hogy alakul a B√©ta param√©ter eset√©ben ha egyv√°ltoz√≥s regresszi√≥r√≥l van sz√≥. Azt is √©rtem hogy a loss f√ºggv√©ny ebben az esetben mi√©rt n√©z ki √∫gy mint egy parabola. De az√©rt szeretn√©k erre Pythonban egy interakt√≠v demonstr√°ci√≥s programot csin√°lni Jupyter Notebokban ahol egyszerre l√°tom a bal oldali plotton hogy alakul a t√©nyleges becsl√©s √©s a jobb oldali plotton hogy alakul a loss. Tudsz seg√≠teni nekem ennek a meg√≠r√°s√°ban?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba260a",
   "metadata": {},
   "source": [
    "Term√©szetesen! Egy interakt√≠v demonstr√°ci√≥s program Jupyter Notebookban remek m√≥dja annak, hogy meg√©rtsd a line√°ris regresszi√≥ m≈±k√∂d√©s√©t √©s a vesztes√©gf√ºggv√©ny alakul√°s√°t a param√©ter (pl. b√©ta) f√ºggv√©ny√©ben.\n",
    "\n",
    "A k√∂vetkez≈ë k√≥d egy interakt√≠v `ipywidgets`-alap√∫ Jupyter Notebook cella, amely:\n",
    "\n",
    "* **Bal oldalon** megmutatja, hogyan illeszkedik a regresszi√≥s egyenes a ponthalmazra adott $\\beta$ (meredeks√©g) √©rt√©k eset√©n.\n",
    "* **Jobb oldalon** megmutatja a vesztes√©gf√ºggv√©nyt (Mean Squared Error) a $\\beta$ √©rt√©k f√ºggv√©ny√©ben, √©s megjel√∂li az aktu√°lis pontot a g√∂rb√©n.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Amit l√°tsz majd:\n",
    "\n",
    "* **Bal oldalt**: az adatokra illeszked≈ë regresszi√≥s egyenes.\n",
    "* **Jobb oldalt**: a vesztes√©g (MSE) g√∂rb√©je a k√ºl√∂nb√∂z≈ë $\\beta$ √©rt√©kek ment√©n.\n",
    "* Egy piros pont jelzi az aktu√°lis $\\beta$ √©rt√©khez tartoz√≥ vesztes√©get.\n",
    "\n",
    "---\n",
    "\n",
    "Ha szeretn√©d b≈ëv√≠teni ezt p√©ld√°ul egy eltol√°ssal ($y = \\beta x + \\alpha$), sz√≠vesen seg√≠tek azt is hozz√°adni!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b776587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from ipywidgets import interact, IntSlider\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1bd81b5",
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Loss f√ºggv√©ny defin√≠ci√≥ja\n",
    "def mse(beta, x, y):\n",
    "    y_pred = beta * x\n",
    "    loss_mse = np.mean((y - y_pred) ** 2)\n",
    "    return loss_mse\n",
    "\n",
    "# Interakt√≠v √°bra rajzol√°sa\n",
    "def plot_regression(beta):\n",
    "    y_pred = beta * x\n",
    "    loss = mse(beta, x, y)\n",
    "    \n",
    "    # B√©ta √©rt√©ktartom√°ny a loss g√∂rb√©hez\n",
    "    beta_vals = np.linspace(-1, 4, 200)\n",
    "    loss_vals = [mse(b, x, y) for b in beta_vals]\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Bal oldali: regresszi√≥s egyenes\n",
    "    axes[0].scatter(x, y, label=\"Adatok\")\n",
    "    axes[0].plot(x, y_pred, color='red', label=f\"Becs√ºlt egyenes: y = {beta:.2f}x\")\n",
    "    axes[0].set_title(\"Line√°ris becsl√©s\")\n",
    "    axes[0].legend()\n",
    "    axes[0].set_xlabel(\"x\")\n",
    "    axes[0].set_ylabel(\"y\")\n",
    "    \n",
    "    # Jobb oldali: loss f√ºggv√©ny\n",
    "    axes[1].plot(beta_vals, loss_vals, label=\"MSE\")\n",
    "    axes[1].scatter([beta], [loss], color='red', zorder=5, label=f\"Loss = {loss:.2f}\")\n",
    "    axes[1].set_title(\"Loss f√ºggv√©ny\")\n",
    "    axes[1].set_xlabel(\"Œ≤ (meredeks√©g)\")\n",
    "    axes[1].set_ylabel(\"Mean Squared Error\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3277c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatok gener√°l√°sa\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 50)\n",
    "true_beta = 2.0\n",
    "y = true_beta * x + np.random.normal(0, 3, size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2c26a097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846802a691dd4fef94f350d79bad53fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='Œ≤', max=4.0, min=-1.0, step=0.05), Output()), _dom_c‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interakt√≠v slider\n",
    "interact(plot_regression, beta=FloatSlider(min=-1, max=4, step=0.05, value=1.0, description=\"Œ≤\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20351848",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>K√∂sz√∂n√∂m ez t√∂k√©letes ha meg tudod csin√°lni ugyan ezt √∫gy is hogy az eltol√°s m√©rt√©ke is benne van √©s a jobb oldali plot 2D helyett 3D az nagyon j√≥ lenne.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b6ec5",
   "metadata": {},
   "source": [
    "Sz√≠vesen! L√©pj√ºnk egy szinttel feljebb: most m√°r nem csak a meredeks√©g ($\\beta$), hanem az **eltol√°s ($\\alpha$)** is v√°ltoztathat√≥. Ehhez a vesztes√©gf√ºggv√©ny m√°r **k√©tv√°ltoz√≥s**, teh√°t a jobb oldali plot egy **3D fel√ºlet**, ahol a pont azt mutatja, hol j√°runk az $(\\alpha, \\beta)$ t√©rben a vesztes√©g szempontj√°b√≥l.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Amit l√°tni fogsz:\n",
    "\n",
    "* **Bal oldalon**: az $y = \\alpha + \\beta x$ egyenes illeszked√©se az adatokra.\n",
    "* **Jobb oldalon**: egy **3D fel√ºlet**, ahol az $x$-tengely $\\alpha$, az $y$-tengely $\\beta$, a $z$-tengely pedig a vesztes√©g (MSE).\n",
    "* Egy piros pont mutatja az aktu√°lis $(\\alpha, \\beta)$ p√°roshoz tartoz√≥ vesztes√©get.\n",
    "\n",
    "---\n",
    "\n",
    "Sz√ºks√©ged van valamilyen b≈ëv√≠t√©sre? P√©ld√°ul:\n",
    "\n",
    "* Gradiensek vizualiz√°l√°sa?\n",
    "* Optim√°lis $(\\alpha, \\beta)$ keres√©se?\n",
    "* Anim√°ci√≥ a lejt≈ë m√≥dszerhez?\n",
    "\n",
    "Sz√≠vesen seg√≠tek azzal is!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43e0a3fd",
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "# Loss f√ºggv√©ny\n",
    "def mse(alpha, beta, x, y):\n",
    "    y_pred = alpha + beta * x\n",
    "    loss_mse = np.mean((y - y_pred) ** 2)\n",
    "    return loss_mse\n",
    "\n",
    "# Interakt√≠v √°bra\n",
    "def plot_regression(alpha, beta, azimuth):\n",
    "    y_pred = alpha + beta * x\n",
    "    loss = mse(alpha, beta, x, y)\n",
    "    \n",
    "    # B√©ta √©s Alfa r√°cs a loss fel√ºlethez\n",
    "    beta_vals = np.linspace(-4, 4, 50)\n",
    "    alpha_vals = np.linspace(-10, 5, 50)\n",
    "    B, A = np.meshgrid(beta_vals, alpha_vals)\n",
    "    Loss = np.array([[mse(a, b, x, y) for b in beta_vals] for a in alpha_vals])\n",
    "    \n",
    "    # Plot setup\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Bal oldali: line√°ris illeszt√©s\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.scatter(x, y, label=\"Adatok\")\n",
    "    ax1.plot(x, y_pred, color='red', label=f\"Becs√ºlt: y = {alpha:.2f} + {beta:.2f}x\")\n",
    "    ax1.set_title(\"Line√°ris becsl√©s\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Jobb oldali: 3D Loss fel√ºlet\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.plot_surface(A, B, Loss, cmap='viridis', alpha=0.3)\n",
    "    ax2.plot_wireframe(A, B, Loss, cmap='viridis', alpha=0.3)\n",
    "    ax2.scatter(alpha, beta, loss, color='red', s=50, label=\"Aktu√°lis Loss\")\n",
    "    ax2.set_title(\"Loss fel√ºlet (MSE)\")\n",
    "    ax2.set_xlabel(\"Œ± (eltol√°s)\")\n",
    "    ax2.set_ylabel(\"Œ≤ (meredeks√©g)\")\n",
    "    ax2.set_zlabel(\"MSE\")\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    ax2.view_init(elev=30, azim=azimuth)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20ce30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatok gener√°l√°sa\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y = true_alpha + true_beta * x + np.random.normal(0, 3, size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b1ce11e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931b04b62dea45d9abfcddb1f22a3f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='Œ±', max=5.0, min=-10.0), FloatSlider(value=2.0, desc‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interakt√≠v vez√©rl≈ëk\n",
    "interact(\n",
    "    plot_regression,\n",
    "    alpha=FloatSlider(min=-10, max=5, step=0.1, value=1.0, description=\"Œ±\"),\n",
    "    beta=FloatSlider(min=-4, max=4, step=0.1, value=2.0, description=\"Œ≤\"),\n",
    "    azimuth=IntSlider(min=-10, max=20, step=1, value=2.0, description=\"Z\")\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3966df6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>K√∂sz√∂n√∂m. Szuper. Meg√©rtettem, hogy milyen kapcsolat van a param√©ter √©s a Vesztes√©g k√∂z√∂tt. L√©pj√ºnk vissza most 2D-be √©s szeretn√©m meg√©rteni ugyan ezt, ugyan ezeken az adatokon de a legegyszer√ºbb l√©tez≈ë neur√°lis h√°l√≥n kereszt√ºl, ahol egyetlen neuron van egyetlen tanh aktiv√°ci√≥s f√ºggv√©nyel. Szeretn√©m l√°tni hogy v√°ltozik a vesztes√©g az egyetlen neuronhoz tartoz√≥ weight f√ºggv√©ny√©ben. Ha ez meg van akkor ut√°na ugyan ezt megcsin√°lhatjuk 3D-ben ugy hogy bias is benne van.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37df927",
   "metadata": {},
   "source": [
    "Nagyszer≈± ir√°ny! Most teh√°t:\n",
    "\n",
    "* Visszat√©r√ºnk **2D-be**, egy **egyetlen neuronhoz**, amely:\n",
    "\n",
    "  * **Egyetlen bemenettel** rendelkezik ($x$),\n",
    "  * Aktiv√°ci√≥s f√ºggv√©nye: $\\tanh(wx)$,\n",
    "  * Nincs **bias** ebben a l√©p√©sben,\n",
    "  * A vesztes√©g: **Mean Squared Error** a val√≥s $y$ √©s a becs√ºlt $\\hat{y} = \\tanh(wx)$ k√∂z√∂tt.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ C√©l:\n",
    "\n",
    "Interakt√≠v Jupyter Notebook plot:\n",
    "\n",
    "* **Bal oldali √°bra**: adatpontok vs. $\\tanh(wx)$ kimenet.\n",
    "* **Jobb oldali √°bra**: vesztes√©g (MSE) v√°ltoz√°sa a **s√∫ly (weight)** √©rt√©k√©nek f√ºggv√©ny√©ben.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Fontos: mi t√∂rt√©nik?\n",
    "\n",
    "Ez m√°r **nem line√°ris modell**. Az aktiv√°ci√≥ ($\\tanh$) miatt a becsl√©s g√∂rb√ºlt lesz, √©s a loss g√∂rbe **nem parabola**, hanem nemline√°ris, t√∂bb sz√©ls≈ë√©rt√©ket is tartalmazhat.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Mit l√°tsz?\n",
    "\n",
    "* **Bal oldalon**: az $\\tanh(wx)$ f√ºggv√©ny kimenete az adatokhoz viszony√≠tva.\n",
    "* **Jobb oldalon**: a s√∫ly (weight) v√°ltoz√°s√°ra hogyan alakul a vesztes√©g (loss).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ K√∂vetkez≈ë l√©p√©s\n",
    "\n",
    "Ha ez megvan, j√∂het a **3D kiterjeszt√©s**, ahol a neuron m√°r:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tanh(wx + b)\n",
    "$$\n",
    "\n",
    "√©s vizualiz√°ljuk a vesztes√©get **$(w, b)$** t√©rben. √çrd meg, ha k√©szen √°llsz r√°, √©s j√∂v√∂k a k√≥ddal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91d34e18",
   "metadata": {
    "code_folding": [
     16
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e7fcadfeba46deb447a869c7707243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=20.0, min=-2.0, step=0.05), Output()), _dom_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adatgener√°l√°s (ugyanaz, mint kor√°bban)\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y = true_alpha + true_beta * x + np.random.normal(0, 3, size=len(x))\n",
    "\n",
    "# Aktiv√°ci√≥s neuron kimenete\n",
    "def neuron_output(w, x):\n",
    "    return np.tanh(w * x)\n",
    "\n",
    "# MSE sz√°m√≠t√°sa\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Interakt√≠v √°bra\n",
    "def plot_neuron_loss(w):\n",
    "    y_pred = neuron_output(w, x)\n",
    "    loss = mse(y, y_pred)\n",
    "    \n",
    "    # Loss g√∂rbe w-re\n",
    "    w_vals = np.linspace(-2, 4, 200)\n",
    "    loss_vals = [mse(y, neuron_output(wi, x)) for wi in w_vals]\n",
    "    \n",
    "    # Plot setup\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Bal oldali: neuron becsl√©s\n",
    "    axes[0].scatter(x, y, label=\"Adatok\")\n",
    "    axes[0].plot(x, y_pred, color='red', label=f\"Neuron kimenet: tanh({w:.2f}¬∑x)\")\n",
    "    axes[0].set_title(\"Neuron becsl√©s (tanh aktiv√°ci√≥)\")\n",
    "    axes[0].set_xlabel(\"x\")\n",
    "    axes[0].set_ylabel(\"y / tanh(wx)\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Jobb oldali: loss g√∂rbe\n",
    "    axes[1].plot(w_vals, loss_vals, label=\"MSE loss\")\n",
    "    axes[1].scatter([w], [loss], color='red', zorder=5, label=f\"Loss = {loss:.2f}\")\n",
    "    axes[1].set_title(\"Loss f√ºggv√©ny (w szerint)\")\n",
    "    axes[1].set_xlabel(\"w (s√∫ly)\")\n",
    "    axes[1].set_ylabel(\"Mean Squared Error\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v slider\n",
    "interact(plot_neuron_loss, w=FloatSlider(min=-2, max=20, step=0.05, value=0.0, description=\"w\"));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e70d19",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>√ârtelek. Itt √∫gy l√°tom, m√°r kezd tr√ºkk√∂ss√© v√°ltozni a probl√©ma mert a tahn √°tviteli f√ºggv√©ny lev√°gja a sz√©ls≈ë √©rt√©keket. Ez√©rt szokt√°k ezek szerint mind a be mind a kimeneti adatokat normaliz√°lni √©s a konkr√©t becsl√©sn√©l visszanormaliz√°lni.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eed10d",
   "metadata": {},
   "source": [
    "\n",
    "Pontosan, nagyon j√≥l l√°tod! Ez egy **kulcsfontoss√°g√∫ felismer√©s** a neur√°lis h√°l√≥zatokkal kapcsolatban.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Mi√©rt normaliz√°lunk?\n",
    "\n",
    "A $\\tanh(z)$ aktiv√°ci√≥s f√ºggv√©ny √©rt√©ktartom√°nya: $(-1, 1)$. Ez **teljesen le fogja v√°gni** az olyan bemeneteket vagy c√©l√©rt√©keket, amelyek ezen a tartom√°nyon k√≠v√ºl esnek, teh√°t:\n",
    "\n",
    "* A bemeneti $x$ √©rt√©keket **t√∫l nagy s√∫llyal (w)** megszorozva a kimenet gyorsan tel√≠t≈ëdik ‚Üí $\\tanh(wx) \\approx \\pm1$,\n",
    "* Ugyanez igaz a **kimeneti (target) $y$** √©rt√©kekre is: ha azok pl. 0‚Äì20 k√∂z√∂tt vannak, de a neuron csak $-1$ √©s $1$ k√∂z√∂tt adhat ki √©rt√©ket, a vesztes√©g sosem lesz kicsi, b√°rmennyire is ‚Äûj√≥‚Äù a w.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Ez√©rt van az, hogy:\n",
    "\n",
    "1. **Bemeneti adatok normaliz√°l√°sa** (pl. min-max vagy z-score):\n",
    "\n",
    "   $$\n",
    "   x_{\\text{norm}} = \\frac{x - \\mu_x}{\\sigma_x}\n",
    "   $$\n",
    "2. **Kimeneti c√©l√©rt√©kek (y) sk√°l√°z√°sa** $[-1, 1]$-re:\n",
    "\n",
    "   $$\n",
    "   y_{\\text{norm}} = \\frac{y - \\min(y)}{\\max(y) - \\min(y)} \\cdot 2 - 1\n",
    "   $$\n",
    "3. Tan√≠t√°s ut√°n vissza lehet sk√°l√°zni a kimenetet a val√≥s tartom√°nyra:\n",
    "\n",
    "   $$\n",
    "   y_{\\text{real}} = \\frac{(y_{\\text{norm}} + 1)}{2} \\cdot (\\max(y) - \\min(y)) + \\min(y)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Kipr√≥b√°lhatjuk:\n",
    "\n",
    "Szeretn√©d, hogy ugyanazt a kis neuronos p√©ld√°t **√∫gy friss√≠ts√ºk**, hogy:\n",
    "\n",
    "* Bemenet √©s kimenet is normaliz√°lva legyen $[-1, 1]$ k√∂z√©,\n",
    "* A loss a normaliz√°lt t√©rben legyen kisz√°molva,\n",
    "* De az els≈ë plot mutassa az **eredeti (visszask√°l√°zott)** kimenetet?\n",
    "\n",
    "Ha igen, 1 percen bel√ºl √∂sszerakom!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277e6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>Igen kiprob√°lhatjuk, de el√∂tte csin√°ld meg nekem m√©g normaliz√°ci√≥ n√©lk√ºl az el√∂z≈ë p√©ld√°t relu aktiv√°ci√≥s f√ºggv√©nnyel is hogy l√°ssam az milyen eredm√©nyt ad. Ut√°na majd megcsin√°ljuk a normaliz√°ci√≥t.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa48d61",
   "metadata": {},
   "source": [
    "Szuper, haladjunk l√©p√©sr≈ël l√©p√©sre! Most j√∂n teh√°t:\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Egyetlen neuron **ReLU aktiv√°ci√≥val**, **normaliz√°l√°s n√©lk√ºl**:\n",
    "\n",
    "* Bemenet: $x$\n",
    "* Kimenet: $\\hat{y} = \\text{ReLU}(wx) = \\max(0, wx)$\n",
    "* Nincs bias\n",
    "* Loss: **MSE**\n",
    "* C√©l: Megn√©zni, hogyan alakul a vesztes√©g (jobb oldali √°bra), √©s milyen a predikci√≥ (bal oldali √°bra)\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Amit l√°tni fogsz:\n",
    "\n",
    "* **Bal oldalon**: az $y = \\max(0, wx)$ kimenet nagyon saj√°tos ‚Äî ha $w < 0$, a kimenet 0 lesz; ha $w > 0$, akkor line√°risan n≈ë, de csak a pozit√≠v tartom√°nyban.\n",
    "* **Jobb oldalon**: a vesztes√©gf√ºggv√©ny nem szimmetrikus, √©s egy√©rtelm≈±en nemline√°ris. Lesz benne egy ‚Äût√∂r√©spont‚Äù $w = 0$ k√∂r√ºl, ahol az akt√≠v √©s nem akt√≠v r√©gi√≥k v√°ltj√°k egym√°st.\n",
    "\n",
    "---\n",
    "\n",
    "Ha ez rendben van, a k√∂vetkez≈ë l√©p√©s j√∂het: **normaliz√°ci√≥**, p√©ld√°ul a $\\tanh$-os p√©ld√°n, ahol ez m√©g fontosabb. Sz√≥lj, √©s j√∂v√∂k azzal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d97d894d",
   "metadata": {
    "code_folding": [
     20
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae0314ff96f4c599565f608a04f14d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=3.0, min=-2.0, step=0.05), Output()), _dom_c‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adatgener√°l√°s (ugyanaz, mint kor√°bban)\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y = true_alpha + true_beta * x + np.random.normal(0, 3, size=len(x))\n",
    "\n",
    "# ReLU aktiv√°ci√≥\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "# Neuron kimenete\n",
    "def neuron_output(w, x):\n",
    "    return relu(w * x)\n",
    "\n",
    "# MSE\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Plot\n",
    "def plot_neuron_loss(w):\n",
    "    y_pred = neuron_output(w, x)\n",
    "    loss = mse(y, y_pred)\n",
    "    \n",
    "    # Loss g√∂rbe\n",
    "    w_vals = np.linspace(-2, 3, 200)\n",
    "    loss_vals = [mse(y, neuron_output(wi, x)) for wi in w_vals]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Bal: becsl√©s\n",
    "    axes[0].scatter(x, y, label=\"Adatok\")\n",
    "    axes[0].plot(x, y_pred, color='red', label=f\"ReLU neuron: max(0, {w:.2f}¬∑x)\")\n",
    "    axes[0].set_title(\"Neuron becsl√©s (ReLU aktiv√°ci√≥)\")\n",
    "    axes[0].set_xlabel(\"x\")\n",
    "    axes[0].set_ylabel(\"y / ReLU(wx)\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Jobb: vesztes√©g\n",
    "    axes[1].plot(w_vals, loss_vals, label=\"MSE loss\")\n",
    "    axes[1].scatter([w], [loss], color='red', zorder=5, label=f\"Loss = {loss:.2f}\")\n",
    "    axes[1].set_title(\"Loss f√ºggv√©ny (w szerint, ReLU)\")\n",
    "    axes[1].set_xlabel(\"w (s√∫ly)\")\n",
    "    axes[1].set_ylabel(\"Mean Squared Error\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v vizsg√°lat\n",
    "interact(plot_neuron_loss, w=FloatSlider(min=-2, max=3, step=0.05, value=0.0, description=\"w\"));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54892581",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>Nagyon j√≥. Most akkor csin√°ljuk meg normaliz√°ci√≥val a tanh √°tviteli f√ºggv√©ny eset√©ben is ugyan ezt.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1e39e",
   "metadata": {},
   "source": [
    "Nagyszer≈±! Most k√∂vetkezik a:\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Normaliz√°lt** v√°ltozat a `tanh` aktiv√°ci√≥s neuronra:\n",
    "\n",
    "**C√©l:**\n",
    "\n",
    "* Bemenet $x$ √©s kimenet $y$ normaliz√°l√°sa $[-1, 1]$ k√∂z√©,\n",
    "* A neuron kimenete: $\\hat{y}_{\\text{norm}} = \\tanh(w \\cdot x_{\\text{norm}})$,\n",
    "* A vesztes√©get a normaliz√°lt t√©rben sz√°moljuk,\n",
    "* **Bal oldali √°br√°n visszask√°l√°zzuk** a kimenetet az eredeti $y$-tartom√°nyba, hogy l√°sd, hogyan illeszkedik a becsl√©s a val√≥di adatokhoz.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Amit itt l√°tsz:\n",
    "\n",
    "* A **bemenet √©s c√©l√©rt√©k normaliz√°lva van**, √≠gy a `tanh` nem tel√≠t≈ëdik olyan gyorsan, √©s sokkal haszn√°lhat√≥bb lesz.\n",
    "* A **loss g√∂rbe sim√°bb**, √©s az optim√°lis √©rt√©k √©rtelmesebb intervallumba ker√ºl.\n",
    "* A **bal oldalon a predikci√≥ vissza van sk√°l√°zva** az eredeti $y$ tartom√°nyba, √≠gy √©rtelmesen illeszkedik az adatokhoz.\n",
    "\n",
    "---\n",
    "\n",
    "K√©szen √°llsz arra, hogy ugyanezt 3D-ben is l√°ssuk, ahol a neuron m√°r **bias**-t is tartalmaz:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{norm}} = \\tanh(wx + b)\n",
    "$$\n",
    "\n",
    "√©s vizsg√°ljuk a vesztes√©gf√ºggv√©nyt a $(w, b)$ t√©rben?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2af97316",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200155d2f1ba420791da4c5bcbf4db14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=3.0, min=-2.0, step=0.05), Output()), _dom_c‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adatok (nem normaliz√°lt)\n",
    "np.random.seed(42)\n",
    "x_raw = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y_raw = true_alpha + true_beta * x_raw + np.random.normal(0, 3, size=len(x_raw))\n",
    "\n",
    "# Normaliz√°l√°s [-1, 1] intervallumba\n",
    "def normalize(arr):\n",
    "    return 2 * (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) - 1\n",
    "\n",
    "def denormalize(arr_norm, original):\n",
    "    return 0.5 * (arr_norm + 1) * (np.max(original) - np.min(original)) + np.min(original)\n",
    "\n",
    "x_norm = normalize(x_raw)\n",
    "y_norm = normalize(y_raw)\n",
    "\n",
    "# Aktiv√°ci√≥\n",
    "def neuron_output(w, x):\n",
    "    return np.tanh(w * x)\n",
    "\n",
    "# Vesztes√©g\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Plot\n",
    "def plot_neuron_loss(w):\n",
    "    y_pred_norm = neuron_output(w, x_norm)\n",
    "    loss = mse(y_norm, y_pred_norm)\n",
    "\n",
    "    # Visszask√°l√°zott kimenet az √°br√°ra\n",
    "    y_pred_rescaled = denormalize(y_pred_norm, y_raw)\n",
    "\n",
    "    # Loss g√∂rbe\n",
    "    w_vals = np.linspace(-2, 3, 200)\n",
    "    loss_vals = [mse(y_norm, neuron_output(wi, x_norm)) for wi in w_vals]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Bal: visszask√°l√°zott predikci√≥\n",
    "    axes[0].scatter(x_raw, y_raw, label=\"Adatok\")\n",
    "    axes[0].plot(x_raw, y_pred_rescaled, color='red', label=f\"Sk√°l√°zott tanh predikci√≥\")\n",
    "    axes[0].set_title(\"Neuron becsl√©s (tanh, visszask√°l√°zva)\")\n",
    "    axes[0].set_xlabel(\"x\")\n",
    "    axes[0].set_ylabel(\"y\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Jobb: vesztes√©g (normaliz√°lt t√©rben)\n",
    "    axes[1].plot(w_vals, loss_vals, label=\"MSE (norm. t√©r)\")\n",
    "    axes[1].scatter([w], [loss], color='red', zorder=5, label=f\"Loss = {loss:.3f}\")\n",
    "    axes[1].set_title(\"Loss f√ºggv√©ny (tanh neuron, normaliz√°lt)\")\n",
    "    axes[1].set_xlabel(\"w (s√∫ly)\")\n",
    "    axes[1].set_ylabel(\"MSE\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v slider\n",
    "interact(plot_neuron_loss, w=FloatSlider(min=-2, max=3, step=0.05, value=0.0, description=\"w\"));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063c71b",
   "metadata": {},
   "source": [
    "<font color='red'>Ugyan ez csak a nem denormaliz√°lt t√©rben is szeretn√©m l√°tni a predit√°lt √©rt√©keket</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d5d5bfa4",
   "metadata": {
    "code_folding": [
     26
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc0f4ab8b914a619ddd1415314e2d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=3.0, min=-2.0, step=0.05), Output()), _dom_c‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adatok (nem normaliz√°lt)\n",
    "np.random.seed(42)\n",
    "x_raw = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y_raw = true_alpha + true_beta * x_raw + np.random.normal(0, 3, size=len(x_raw))\n",
    "\n",
    "# Normaliz√°l√°s [-1, 1] intervallumba\n",
    "def normalize(arr):\n",
    "    return 2 * (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) - 1\n",
    "\n",
    "def denormalize(arr_norm, original):\n",
    "    return 0.5 * (arr_norm + 1) * (np.max(original) - np.min(original)) + np.min(original)\n",
    "\n",
    "x_norm = normalize(x_raw)\n",
    "y_norm = normalize(y_raw)\n",
    "\n",
    "# Aktiv√°ci√≥\n",
    "def neuron_output(w, x):\n",
    "    return np.tanh(w * x)\n",
    "\n",
    "# Vesztes√©g\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Plot\n",
    "def plot_neuron_loss(w):\n",
    "    y_pred_norm = neuron_output(w, x_norm)\n",
    "    loss = mse(y_norm, y_pred_norm)\n",
    "\n",
    "    # Visszask√°l√°zott kimenet az √°br√°ra\n",
    "    y_pred_rescaled = denormalize(y_pred_norm, y_raw)\n",
    "\n",
    "    # Loss g√∂rbe\n",
    "    w_vals = np.linspace(-2, 3, 200)\n",
    "    loss_vals = [mse(y_norm, neuron_output(wi, x_norm)) for wi in w_vals]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "    # Bal: nem visszask√°l√°zott predikci√≥\n",
    "    axes[0].scatter(x_raw, y_raw, label=\"Adatok\")\n",
    "    axes[0].plot(x_raw, y_pred_rescaled, color='red', label=f\"Sk√°l√°zott tanh predikci√≥\")\n",
    "    axes[0].set_title(\"Neuron becsl√©s (tanh, visszask√°l√°zva)\")\n",
    "    axes[0].set_xlabel(\"x\")\n",
    "    axes[0].set_ylabel(\"y\")\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # K√∂z√©ps≈ë: visszask√°l√°zott predikci√≥\n",
    "    axes[1].scatter(x_raw, y_norm, label=\"Adatok\")\n",
    "    axes[1].plot(x_raw, y_pred_norm, color='red', label=f\"Sk√°l√°zott tanh predikci√≥\")\n",
    "    axes[1].set_title(\"Neuron becsl√©s (tanh, visszask√°l√°zva)\")\n",
    "    axes[1].set_xlabel(\"x\")\n",
    "    axes[1].set_ylabel(\"y_norm\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Jobb: vesztes√©g (normaliz√°lt t√©rben)\n",
    "    axes[2].plot(w_vals, loss_vals, label=\"MSE (norm. t√©r)\")\n",
    "    axes[2].scatter([w], [loss], color='red', zorder=5, label=f\"Loss = {loss:.3f}\")\n",
    "    axes[2].set_title(\"Loss f√ºggv√©ny (tanh neuron, normaliz√°lt)\")\n",
    "    axes[2].set_xlabel(\"w (s√∫ly)\")\n",
    "    axes[2].set_ylabel(\"MSE\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v slider\n",
    "interact(plot_neuron_loss, w=FloatSlider(min=-2, max=3, step=0.05, value=0.0, description=\"w\"));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5ff4e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>Fantasztikus. J√≥l sejtem, hogy ha a normaliz√°ci√≥ j√≥ volt, akkor ebben az esetben a 0 bias mellett lesz a legjobb, a legalacsonyabb a loss?</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a36dce",
   "metadata": {},
   "source": [
    "Nagyon j√≥ k√©rd√©s ‚Äî √©s **igen, az intu√≠ci√≥d helyes**: ha a **normaliz√°ci√≥ j√≥l siker√ºlt**, akkor val√≥ban **az optim√°lis bias √©rt√©k k√∂zel lesz a null√°hoz**.\n",
    "\n",
    "---\n",
    "\n",
    "### ü§î Mi√©rt?\n",
    "\n",
    "A `tanh(wx + b)` aktiv√°ci√≥s neuron **szimmetrikus** a nulla k√∂r√ºl, √©s ha:\n",
    "\n",
    "* a **bemenet $x$** normaliz√°lva van $[-1, 1]$ k√∂z√©,\n",
    "* a **kimenet $y$** is szimmetrikusan normaliz√°lva van $[-1, 1]$ k√∂z√©,\n",
    "\n",
    "akkor az a **legegyszer≈±bb** eset, amikor a neuron √©ppen k√∂z√©pen, az orig√≥ k√∂r√ºl ‚Äûmozog‚Äù, azaz:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tanh(wx + \\underbrace{0}_{\\text{optim√°lis } b?})\n",
    "$$\n",
    "\n",
    "Ebben az esetben **nincs sz√ºks√©g eltol√°sra**, mert a bemenet √©s a c√©l√©rt√©k is **k√∂z√©pre van h√∫zva**. A rendszer kv√°zi m√°r ‚Äûk√∂z√©pen van‚Äù, √≠gy a legjobb illeszt√©s **ak√°r z√©r√≥ bias mellett is el√©rhet≈ë**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ DE: van egy ‚Äûde‚Äù!\n",
    "\n",
    "A gyakorlatban:\n",
    "\n",
    "* ha a normaliz√°ci√≥ **nem t√∂k√©letesen szimmetrikus** (pl. az $x$ eloszl√°sa nem k√∂z√©pre van koncentr√°lva),\n",
    "* vagy ha az **adatok nem line√°risan illeszkednek** a `tanh`-ra,\n",
    "\n",
    "akkor a modell lehet, hogy **picike, de nem nulla bias √©rt√©kkel** tudja el√©rni a minim√°lis vesztes√©get.\n",
    "\n",
    "---\n",
    "\n",
    "### üî≠ Mi k√∂vetkezik?\n",
    "\n",
    "Ha szeretn√©d, **megmutatom 3D-ben**, hogyan alakul a vesztes√©g a $(w, b)$ t√©rben, ugyan√≠gy normaliz√°lt bemenettel √©s kimenettel. Ott l√°thatod majd:\n",
    "\n",
    "* hol van a glob√°lis minimum,\n",
    "* vajon t√©nyleg $b \\approx 0$-n√°l alakul-e ki a legkisebb MSE.\n",
    "\n",
    "Sz√≥lj, √©s hozom a 3D-s interakt√≠v p√©ld√°t!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62dc35d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>K√∂sz√∂n√∂m a javaslatot folytassuk √≠gy n√©zz√ºk meg 3D-ben hogyan alakult volt a vesztes√©g a bias √©s a weigt f√ºggv√©ny√©ben.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d83bd",
   "metadata": {},
   "source": [
    "Nagyszer≈±, most j√∂n a **v√°rva v√°rt 3D-s vizualiz√°ci√≥**! üéØ\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 3D Loss t√©rk√©p `tanh(wx + b)` neuronhoz normaliz√°lt adatokkal\n",
    "\n",
    "**Mit fogsz l√°tni?**\n",
    "\n",
    "* A vesztes√©g (MSE) alakul√°sa egyetlen neuron eset√©n,\n",
    "* Aktiv√°ci√≥: `tanh`,\n",
    "* Bemenet √©s kimenet: **normaliz√°lt $[-1, 1]$**,\n",
    "* Kimenet: $\\hat{y} = \\tanh(w x + b)$,\n",
    "* Loss t√©r: $(w, b) \\mapsto \\text{MSE}$\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Amit ki tudsz olvasni:\n",
    "\n",
    "* **Hol van a loss minimuma**?\n",
    "  ‚Üí V√°rhat√≥an valahol a $b \\approx 0$, $w \\approx 1-2$ k√∂r√ºl, ha a normaliz√°ci√≥ j√≥l siker√ºlt.\n",
    "\n",
    "* **Hogyan alakul a fel√ºlet**?\n",
    "  ‚Üí Nem konvex, nem szimmetrikus, de sokkal √©rtelmesebb form√°j√∫, mint normaliz√°ci√≥ n√©lk√ºl.\n",
    "\n",
    "---\n",
    "\n",
    "Sz√≠vesen seg√≠tek a k√∂vetkez≈ë l√©p√©sben is:\n",
    "\n",
    "* Lejt≈ë m√≥dszer vizualiz√°l√°sa a $(w, b)$ t√©ren?\n",
    "* T√∂bb neuron?\n",
    "* M√°s aktiv√°ci√≥s f√ºggv√©ny?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c7c9c0b",
   "metadata": {
    "code_folding": [
     26
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0983550115fd40dfa344f335bc402735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=3.0, min=-3.0), FloatSlider(value=0.0, descr‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eredeti adatok\n",
    "np.random.seed(42)\n",
    "x_raw = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y_raw = true_alpha + true_beta * x_raw + np.random.normal(0, 3, size=len(x_raw))\n",
    "\n",
    "# Normaliz√°l√°s [-1, 1]\n",
    "def normalize(arr):\n",
    "    return 2 * (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) - 1\n",
    "\n",
    "def denormalize(arr_norm, original):\n",
    "    return 0.5 * (arr_norm + 1) * (np.max(original) - np.min(original)) + np.min(original)\n",
    "\n",
    "x_norm = normalize(x_raw)\n",
    "y_norm = normalize(y_raw)\n",
    "\n",
    "# Neuron kimenet tanh(wx + b)\n",
    "def neuron_output(w, b, x):\n",
    "    return np.tanh(w * x + b)\n",
    "\n",
    "# MSE\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Interakt√≠v 3D plot\n",
    "def plot_neuron_3d(w, b, azimuth):\n",
    "    y_pred_norm = neuron_output(w, b, x_norm)\n",
    "    y_pred_rescaled = denormalize(y_pred_norm, y_raw)\n",
    "    loss = mse(y_norm, y_pred_norm)\n",
    "\n",
    "    # Loss t√©r kisz√°m√≠t√°sa\n",
    "    w_vals = np.linspace(-3, 3, 50)\n",
    "    b_vals = np.linspace(-3, 3, 50)\n",
    "    W, B = np.meshgrid(w_vals, b_vals)\n",
    "    Loss = np.array([[mse(y_norm, neuron_output(w_, b_, x_norm)) for w_, b_ in zip(row_w, row_b)]\n",
    "                     for row_w, row_b in zip(W, B)])\n",
    "\n",
    "    # √Åbr√°zol√°s\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Bal: eredeti sk√°l√°ra visszahozott predikci√≥\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.scatter(x_raw, y_raw, label=\"Adatok\")\n",
    "    ax1.plot(x_raw, y_pred_rescaled, color='red', label=f\"Predikci√≥: tanh({w:.2f}¬∑x + {b:.2f})\")\n",
    "    ax1.set_title(\"Becs√ºlt predikci√≥ (visszask√°l√°zva)\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Jobb: 3D Loss t√©r\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.plot_surface(W, B, Loss, cmap='viridis', alpha=0.8)\n",
    "    ax2.plot_wireframe(W, B, Loss, cmap='viridis', alpha=0.8)\n",
    "    ax2.scatter(w, b, loss, color='red', s=50, label=f\"Loss = {loss:.3f}\")\n",
    "    ax2.set_title(\"Loss t√©r (w, b) szerint\")\n",
    "    ax2.set_xlabel(\"w (s√∫ly)\")\n",
    "    ax2.set_ylabel(\"b (bias)\")\n",
    "    ax2.set_zlabel(\"MSE\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    \n",
    "    ax2.view_init(elev=20, azim=azimuth)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v vez√©rl≈ëk\n",
    "interact(\n",
    "    plot_neuron_3d,\n",
    "    w   = FloatSlider(min=-3,  max=3,  step=0.1, value=0.0, description=\"w\"),\n",
    "    b   = FloatSlider(min=-3,  max=3,  step=0.1, value=0.0, description=\"b\"),\n",
    "    azimuth=IntSlider(min=-90, max=90, step=1.0, value=0.0, description=\"Z\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4616f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>Rendk√≠v√ºl l√°tv√°nyos lett az √°br√°zol√°s k√∂sz√∂n√∂m. Sz√≥val az √©n intuici√≥m az hogy ebben a p√©ld√°ban b√°rmilyen beta √©s w √©rt√©ket veszek fel mindig ki lehet sz√°molni a gradienst √©s el≈ëbb ut√≥bb el lehet jutni ez alapj√°n a glob√°lis minimumhoz. Ez√©rt el≈ësz√∂r arra szeretn√©lek k√©rni hogy 3D plotra valahogy rajzoljuk fel azt is hogy az √©ppen aktu√°lisan v√°lasztott beta √©s weight √©rt√©kekn√©l mi a gradiens √©s merre mutat.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e65d5",
   "metadata": {},
   "source": [
    "Nagyon √∂r√ºl√∂k, hogy tetszik az √°br√°zol√°s ‚Äî √©s **ism√©t pontosan r√°√©rezt√©l a l√©nyegre**! üéØ\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Amit mondasz, az igaz:\n",
    "\n",
    "Ilyen egyszer≈± h√°l√≥zatn√°l (egy `tanh` neuron, normaliz√°lt adatokkal), a **vesztes√©gfel√ºlet sz√©p √©s sima**, √©s a gradiens **minden pontban kisz√°molhat√≥**. Emiatt a **gradiens alap√∫ m√≥dszerek** ‚Äî mint a gradient descent ‚Äî **j√≥ es√©llyel** eljutnak a **glob√°lis minimumhoz**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Amit most megcsin√°lunk:\n",
    "\n",
    "A megl√©v≈ë 3D plotba **berajzoljuk a gradienst** az aktu√°lis $(w, b)$ pontban:\n",
    "\n",
    "* A gradiens: $\\nabla L(w, b) = \\left[ \\frac{\\partial L}{\\partial w}, \\frac{\\partial L}{\\partial b} \\right]$\n",
    "* Ez egy **ny√≠l** a $(w, b, \\text{loss})$ pontb√≥l, amely a **meredeks√©g ir√°ny√°ba mutat**\n",
    "* Figyelem: a gradiens **a vesztes√©g N√ñVEKED√âS√âNEK** ir√°nya ‚Äî az **ellenkez≈ë ir√°nyba kell majd l√©pni** a cs√∂kkent√©shez\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Friss√≠tett k√≥d gradiens ny√≠llal:\n",
    "\n",
    "### üîç Mit figyelj?\n",
    "\n",
    "* A piros ny√≠l a **vesztes√©g cs√∂kkent√©s√©nek ir√°ny√°t** mutatja: ezt k√∂vetn√© a gradient descent.\n",
    "* Mozgasd a `w` √©s `b` cs√∫szk√°t, √©s figyeld, hogyan **v√°ltozik a ny√≠l ir√°nya** a vesztes√©gfelsz√≠nen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90d22e9f",
   "metadata": {
    "code_folding": [
     40
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd641205310d41a080ec6a114b287742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=3.0, min=-3.0), FloatSlider(value=0.0, descr‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eredeti adatok\n",
    "np.random.seed(42)\n",
    "x_raw = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y_raw = true_alpha + true_beta * x_raw + np.random.normal(0, 3, size=len(x_raw))\n",
    "\n",
    "# Normaliz√°l√°s\n",
    "def normalize(arr):\n",
    "    return 2 * (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) - 1\n",
    "\n",
    "def denormalize(arr_norm, original):\n",
    "    return 0.5 * (arr_norm + 1) * (np.max(original) - np.min(original)) + np.min(original)\n",
    "\n",
    "x_norm = normalize(x_raw)\n",
    "y_norm = normalize(y_raw)\n",
    "\n",
    "# Neuron kimenet\n",
    "def neuron_output(w, b, x):\n",
    "    return np.tanh(w * x + b)\n",
    "\n",
    "# Vesztes√©g\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Gradiens sz√°m√≠t√°sa (analitikusan)\n",
    "def grad_mse_tanh(w, b, x, y_true):\n",
    "    z = w * x + b\n",
    "    y_pred = np.tanh(z)\n",
    "    dL_dy = 2 * (y_pred - y_true) / len(x)\n",
    "    dy_dz = 1 - np.tanh(z)**2\n",
    "    dz_dw = x\n",
    "    dz_db = 1\n",
    "\n",
    "    dL_dw = np.sum(dL_dy * dy_dz * dz_dw)\n",
    "    dL_db = np.sum(dL_dy * dy_dz * dz_db)\n",
    "\n",
    "    return dL_dw, dL_db\n",
    "\n",
    "# Plot\n",
    "def plot_neuron_3d_with_gradient(w, b, azimuth):\n",
    "    y_pred_norm = neuron_output(w, b, x_norm)\n",
    "    y_pred_rescaled = denormalize(y_pred_norm, y_raw)\n",
    "    loss = mse(y_norm, y_pred_norm)\n",
    "\n",
    "    # Gradiens a (w,b) pontban\n",
    "    grad_w, grad_b = grad_mse_tanh(w, b, x_norm, y_norm)\n",
    "\n",
    "    # Loss t√©r\n",
    "    w_vals = np.linspace(-3, 3, 50)\n",
    "    b_vals = np.linspace(-3, 3, 50)\n",
    "    W, B = np.meshgrid(w_vals, b_vals)\n",
    "    Loss = np.array([[mse(y_norm, neuron_output(w_, b_, x_norm)) for w_, b_ in zip(row_w, row_b)]\n",
    "                     for row_w, row_b in zip(W, B)])\n",
    "\n",
    "    # √Åbra\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Bal: predikci√≥ (visszask√°l√°zva)\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.scatter(x_raw, y_raw, label=\"Adatok\")\n",
    "    ax1.plot(x_raw, y_pred_rescaled, color='red', label=f\"Predikci√≥: tanh({w:.2f}¬∑x + {b:.2f})\")\n",
    "    ax1.set_title(\"Becs√ºlt predikci√≥ (visszask√°l√°zva)\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Jobb: 3D loss + gradiens ny√≠l\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.plot_surface(W, B, Loss, cmap='viridis', alpha=0.8)\n",
    "    ax2.scatter(w, b, loss, color='red', s=50, label=\"Aktu√°lis pont\")\n",
    "\n",
    "    # Gradiens ny√≠l (az ellenkez≈ë ir√°ny mutatja a cs√∂kken√©st!)\n",
    "    scale = 0.3  # ny√≠l hossza\n",
    "    ax2.quiver(w, b, loss, -grad_w, -grad_b, 0, color='red', length=scale, normalize=True)\n",
    "\n",
    "    ax2.set_title(\"Loss t√©r gradienssel\")\n",
    "    ax2.set_xlabel(\"w\")\n",
    "    ax2.set_ylabel(\"b\")\n",
    "    ax2.set_zlabel(\"MSE\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    ax2.view_init(elev=20, azim=azimuth)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v\n",
    "interact(\n",
    "    plot_neuron_3d_with_gradient,\n",
    "    w   = FloatSlider(min=-3,  max=3,  step=0.1, value=0.0, description=\"w\"),\n",
    "    b   = FloatSlider(min=-3,  max=3,  step=0.1, value=0.0, description=\"b\"),\n",
    "    azimuth=IntSlider(min=-90, max=90, step=1.0, value=0.0, description=\"Z\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f9ded",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>K√∂sz√∂n√∂m. Szuper lett ez is. De alig l√°tom a gradienst jelz≈ë nyilat. Lehetne jav√≠tani azon hogy vizu√°lisan jobban l√°ssam?</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d6975",
   "metadata": {},
   "source": [
    "√ñr√ºl√∂k, hogy tetszik! √âs igen ‚Äî teljesen jogos az √©szrev√©teled: a 3D ploton az alap√©rtelmezett ny√≠l sajnos **nagyon r√∂vid √©s lapos** lehet, f≈ëleg, ha a gradiens komponensei kicsik.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Mit tudunk jav√≠tani?\n",
    "\n",
    "1. **Ny√≠l t√©rbeli komponens√©nek (z-ir√°ny) megad√°sa**:\n",
    "\n",
    "   * Eddig a ny√≠l csak a **(w, b)** s√≠kban mozgott, nem volt m√©lys√©ge.\n",
    "   * Most m√°r a ny√≠l mutatni fogja, hogy **a loss √©rt√©k is cs√∂kken** ‚Äî azaz lefel√© fog mutatni a fel√ºleten!\n",
    "   * Be√°ll√≠tjuk:\n",
    "\n",
    "     $$\n",
    "     \\text{ir√°ny} = (-\\frac{\\partial L}{\\partial w}, -\\frac{\\partial L}{\\partial b}, -\\|\\nabla L\\|)\n",
    "     $$\n",
    "\n",
    "2. **Ny√≠l m√©ret√©nek vizu√°lis felsk√°l√°z√°sa**, hogy jobban √©szrevehet≈ë legyen.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Most:\n",
    "\n",
    "* A **ny√≠l vastagabb, hosszabb**, 3D-ben mutat lefel√© a fel√ºleten.\n",
    "* Jelzi, **merre kellene elindulni**, ha le akarjuk cs√∂kkenteni a vesztes√©get.\n",
    "* A `quiver` most **minden tengely ment√©n vizualiz√°lja** a mozg√°st ‚Äî √≠gy sokkal l√°tv√°nyosabb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18c14bad",
   "metadata": {
    "code_folding": [
     40
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda9d7e4382945f0b30851ea4d6ca5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=3.0, min=-3.0), FloatSlider(value=0.0, descr‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adatok\n",
    "np.random.seed(42)\n",
    "x_raw = np.linspace(0, 10, 50)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y_raw = true_alpha + true_beta * x_raw + np.random.normal(0, 3, size=len(x_raw))\n",
    "\n",
    "# Normaliz√°l√°s\n",
    "def normalize(arr):\n",
    "    return 2 * (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) - 1\n",
    "\n",
    "def denormalize(arr_norm, original):\n",
    "    return 0.5 * (arr_norm + 1) * (np.max(original) - np.min(original)) + np.min(original)\n",
    "\n",
    "x_norm = normalize(x_raw)\n",
    "y_norm = normalize(y_raw)\n",
    "\n",
    "# Neuron kimenet\n",
    "def neuron_output(w, b, x):\n",
    "    return np.tanh(w * x + b)\n",
    "\n",
    "# MSE\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Gradiens sz√°m√≠t√°sa\n",
    "def grad_mse_tanh(w, b, x, y_true):\n",
    "    z = w * x + b\n",
    "    y_pred = np.tanh(z)\n",
    "    dL_dy = 2 * (y_pred - y_true) / len(x)\n",
    "    dy_dz = 1 - np.tanh(z)**2\n",
    "    dz_dw = x\n",
    "    dz_db = 1\n",
    "\n",
    "    dL_dw = np.sum(dL_dy * dy_dz * dz_dw)\n",
    "    dL_db = np.sum(dL_dy * dy_dz * dz_db)\n",
    "\n",
    "    return dL_dw, dL_db\n",
    "\n",
    "# Plot\n",
    "def plot_neuron_3d_with_gradient(w, b, azimuth):\n",
    "    y_pred_norm = neuron_output(w, b, x_norm)\n",
    "    y_pred_rescaled = denormalize(y_pred_norm, y_raw)\n",
    "    loss = mse(y_norm, y_pred_norm)\n",
    "\n",
    "    # Gradiens\n",
    "    grad_w, grad_b = grad_mse_tanh(w, b, x_norm, y_norm)\n",
    "    grad_norm = np.sqrt(grad_w**2 + grad_b**2)\n",
    "    grad_z = grad_norm  # z ir√°nyban mutat lefel√©\n",
    "\n",
    "    # Loss t√©r\n",
    "    w_vals = np.linspace(-3, 3, 50)\n",
    "    b_vals = np.linspace(-3, 3, 50)\n",
    "    W, B = np.meshgrid(w_vals, b_vals)\n",
    "    Loss = np.array([[mse(y_norm, neuron_output(w_, b_, x_norm)) for w_, b_ in zip(row_w, row_b)]\n",
    "                     for row_w, row_b in zip(W, B)])\n",
    "\n",
    "    # √Åbra\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Bal: predikci√≥\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.scatter(x_raw, y_raw, label=\"Adatok\")\n",
    "    ax1.plot(x_raw, y_pred_rescaled, color='red', label=f\"Predikci√≥: tanh({w:.2f}¬∑x + {b:.2f})\")\n",
    "    ax1.set_title(\"Becs√ºlt predikci√≥ (visszask√°l√°zva)\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Jobb: 3D loss + gradiens ny√≠l\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.plot_surface(W, B, Loss, cmap='viridis', alpha=0.8)\n",
    "    ax2.scatter(w, b, loss, color='red', s=50, label=\"Aktu√°lis pont\")\n",
    "\n",
    "    # Nagyobb, 3D ny√≠l\n",
    "    scale = 1.0\n",
    "    ax2.quiver(\n",
    "        w, b, loss,              # kezd≈ëpont\n",
    "        -grad_w, -grad_b, -grad_z,  # ir√°ny (neg√°lt!)\n",
    "        color='red', linewidth=2, arrow_length_ratio=0.2, length=scale, normalize=True\n",
    "    )\n",
    "\n",
    "    ax2.set_title(\"Loss t√©r gradiens ir√°ny√°val\")\n",
    "    ax2.set_xlabel(\"w (s√∫ly)\")\n",
    "    ax2.set_ylabel(\"b (bias)\")\n",
    "    ax2.set_zlabel(\"MSE\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    ax2.view_init(elev=20, azim=azimuth)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interakt√≠v\n",
    "interact(\n",
    "    plot_neuron_3d_with_gradient,\n",
    "    w   = FloatSlider(min=-3,  max=3,  step=0.1, value=0.0, description=\"w\"),\n",
    "    b   = FloatSlider(min=-3,  max=3,  step=0.1, value=0.0, description=\"b\"),\n",
    "    azimuth=IntSlider(min=-90, max=90, step=1.0, value=0.0, description=\"Z\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac6f76",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>√ârtelek. Sz√≥val eddig a pontig tudtuk √°br√°zolni a vesztes√©ged 3D plotton. De ha nem egy hanem k√©t neuron lenne akkor m√°r nem tudjuk a k√©t s√∫ly √©s a k√©t gradiens f√ºggv√©ny√©ben √°br√°zolni a vesztes√©get. Ez√©rt innent≈ël kezdve m√°r nem tudom vizu√°lisan √°br√°zolni, de a k√©rd√©sem az, hogy ha 2 neuronom lenne akkor is van egy glob√°lis minimuma a vesztes√©gf√ºggv√©nynek viszont lehet hogy vannak olyan weight √©s bias be√°ll√≠t√°sok ahonnan a gradiens m√≥dzserrel ebben a fenti p√©ld√°ban nem lehet eljutni a glob√°lis miniumumhoz, vagy ebben a p√©ld√°ban nincs ilyen √©s el≈ëbb vagy ut√≥bb biztosan el lehet jutni a glob√°lis minimumhoz?</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7b965",
   "metadata": {},
   "source": [
    "Ez **zseni√°lis k√©rd√©s** ‚Äì √©s val√≥ban **itt kezd bonyol√≥dni a t√∂rt√©net**. Vizsg√°ljuk meg alaposan:\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Alapfel√°ll√°s: 2 neuron (p√©ld√°ul rejtett r√©teg 2 neuronja)\n",
    "\n",
    "A h√°l√≥zat szerkezete √≠gy n√©zhet ki:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tanh(w_1 x + b_1) + \\tanh(w_2 x + b_2)\n",
    "$$\n",
    "\n",
    "Ez m√©g mindig:\n",
    "\n",
    "* **Egyv√°ltoz√≥s bemenet**,\n",
    "* Egyetlen kimenet,\n",
    "* De m√°r **nemline√°ris kombin√°ci√≥** k√©t komponensb≈ël.\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ Vesztes√©gf√ºggv√©ny jellege\n",
    "\n",
    "Itt m√°r a vesztes√©gf√ºggv√©ny nem csak **sima, hanem sokdimenzi√≥s √©s nem konvex**. A param√©tert√©r:\n",
    "\n",
    "* $w_1, b_1, w_2, b_2$ ‚Üí **4 dimenzi√≥s**\n",
    "* Ezt **nem tudjuk √°br√°zolni**, de tudjuk **vizsg√°lni az alakj√°t** √©s **elm√©letileg k√∂vetkeztetni**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùì Van-e glob√°lis minimum?\n",
    "\n",
    "### ‚úÖ Igen, **van glob√°lis minimum**, mivel:\n",
    "\n",
    "* A vesztes√©gf√ºggv√©ny (MSE) **nem negat√≠v**, √©s le van szor√≠tva alulr√≥l (0),\n",
    "* A s√∫lyok valamilyen √©rt√©kein√©l biztosan el√©rhet≈ë minim√°lis MSE (hiszen p√©ld√°ul **a tanul√°si feladat j√≥l meghat√°rozott**).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùì El tudunk-e **biztosan** jutni oda gradient descenttel?\n",
    "\n",
    "### R√∂vid v√°lasz: **nem mindig**.\n",
    "\n",
    "### Mi√©rt?\n",
    "\n",
    "Mert a vesztes√©gfelsz√≠n **nem konvex**:\n",
    "\n",
    "* Lehetnek **lok√°lis minimumok**,\n",
    "* Lehetnek **nyergek** (saddle point),\n",
    "* Lehetnek **lapos r√©gi√≥k**, ahol a gradiens gyenge vagy null√°hoz k√∂zeli,\n",
    "* √âs lehet, hogy a gradient descent ezek egyik√©be ‚Äûbeleragad‚Äù.\n",
    "\n",
    "> **P√©lda**: k√©t neuron pont ellent√©tes s√∫lyokat tanul, √≠gy ‚Äûkioltj√°k egym√°st‚Äù ‚Äî ekkor a gradiens 0 lehet, de nem √©rt√ºnk el minim√°lis vesztes√©get.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå De ebben a konkr√©t p√©ld√°ban?\n",
    "\n",
    "Ez m√©g egy **viszonylag egyszer≈± regresszi√≥s feladat** (egyv√°ltoz√≥s bemenet, sima target), √≠gy:\n",
    "\n",
    "* Ha **az inicializ√°l√°s j√≥** (nem extr√©m messze van a megold√°st√≥l),\n",
    "* √âs ha a **tanul√°si r√°ta megfelel≈ë**,\n",
    "  akkor **val√≥sz√≠n≈±leg** eljut a gradient descent a **glob√°lis minimum k√∂zel√©be**, vagy legal√°bb egy **j√≥ minimumba**.\n",
    "\n",
    "De **matematikailag nincs garancia** r√°, hogy mindig megtal√°lja a glob√°lis minimumot.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ √ñsszefoglalva:\n",
    "\n",
    "| Tulajdons√°g                         | 1 neuron             | 2 neuron          |\n",
    "| ----------------------------------- | -------------------- | ----------------- |\n",
    "| Vizualiz√°lhat√≥ vesztes√©gfelsz√≠n     | ‚úÖ                    | ‚ùå (4D-ben van)    |\n",
    "| Nemkonvex f√ºggv√©ny?                 | ‚úÖ (enyh√©n)           | ‚úÖ (sokkal ink√°bb) |\n",
    "| Van glob√°lis minimum?               | ‚úÖ                    | ‚úÖ                 |\n",
    "| Gradient descent mindig megtal√°lja? | üí° Val√≥sz√≠n≈±leg      | ‚ùå Nem garant√°lt   |\n",
    "| F√ºgg az inicializ√°l√°st√≥l?           | ‚ùå (kisebb m√©rt√©kben) | ‚úÖ Jelent≈ësen      |\n",
    "\n",
    "---\n",
    "\n",
    "### Ha √©rdekel:\n",
    "\n",
    "Tudok neked csin√°lni egy olyan k√≥dot, ahol:\n",
    "\n",
    "* 2 neuronos h√°l√≥t tan√≠tunk,\n",
    "* √âs v√©gigk√∂vetj√ºk, hogyan cs√∂kken a vesztes√©g,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4b471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1bc74a8",
   "metadata": {},
   "source": [
    "Szuper! Most k√©sz√≠t√ºnk egy **2 neuronos neur√°lis h√°l√≥t**, amely:\n",
    "\n",
    "* Egy bemenetet vesz fel: $x$,\n",
    "* K√©t rejtett neuront haszn√°l: $\\tanh(w_1 x + b_1)$ √©s $\\tanh(w_2 x + b_2)$,\n",
    "* Ezeket **√∂sszeadjuk** (line√°ris kimeneti r√©teg),\n",
    "* Tan√≠tjuk **gradiens m√≥dszerrel** (gradient descent),\n",
    "* Vizu√°lisan mutatjuk:\n",
    "\n",
    "  * Hogyan v√°ltozik a **predikci√≥** minden iter√°ci√≥ban,\n",
    "  * Hogyan cs√∂kken a **vesztes√©g**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Mit kapsz?\n",
    "\n",
    "* **Bal oldalon**: a 2 neuronos h√°l√≥ v√©gs≈ë kimenete (visszask√°l√°zva), √∂sszevetve az eredeti adatokkal.\n",
    "* **Jobb oldalon**: a vesztes√©g **cs√∂kken√©s√©nek folyamata** az epochok sor√°n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a860f3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eredeti adatok\n",
    "np.random.seed(42)\n",
    "x_raw = np.linspace(0, 10, 100)\n",
    "true_alpha = 1.0\n",
    "true_beta = 2.0\n",
    "y_raw = true_alpha + true_beta * x_raw + np.random.normal(0, 3, size=len(x_raw))\n",
    "\n",
    "# Normaliz√°l√°s [-1, 1]\n",
    "def normalize(arr):\n",
    "    return 2 * (arr - np.min(arr)) / (np.max(arr) - np.min(arr)) - 1\n",
    "\n",
    "def denormalize(arr_norm, original):\n",
    "    return 0.5 * (arr_norm + 1) * (np.max(original) - np.min(original)) + np.min(original)\n",
    "\n",
    "x = normalize(x_raw)\n",
    "y = normalize(y_raw)\n",
    "\n",
    "# Aktiv√°ci√≥\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "# 2 neuronos h√°l√≥ kimenete\n",
    "def forward_pass(x, w1, b1, w2, b2):\n",
    "    z1 = w1 * x + b1\n",
    "    z2 = w2 * x + b2\n",
    "    a1 = tanh(z1)\n",
    "    a2 = tanh(z2)\n",
    "    y_hat = a1 + a2\n",
    "    return y_hat, z1, z2, a1, a2\n",
    "\n",
    "# Loss\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Gradient descent tan√≠t√°s\n",
    "epochs = 200\n",
    "lr = 0.05\n",
    "\n",
    "# S√∫lyok inicializ√°l√°sa\n",
    "w1, b1 = np.random.randn(), np.random.randn()\n",
    "w2, b2 = np.random.randn(), np.random.randn()\n",
    "\n",
    "loss_history = []\n",
    "pred_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_hat, z1, z2, a1, a2 = forward_pass(x, w1, b1, w2, b2)\n",
    "    loss = mse(y, y_hat)\n",
    "    loss_history.append(loss)\n",
    "    pred_history.append(y_hat.copy())\n",
    "\n",
    "    # Backpropagation\n",
    "    dL_dy = 2 * (y_hat - y) / len(x)\n",
    "\n",
    "    dy_da1 = 1\n",
    "    dy_da2 = 1\n",
    "\n",
    "    da1_dz1 = tanh_deriv(z1)\n",
    "    da2_dz2 = tanh_deriv(z2)\n",
    "\n",
    "    dz1_dw1 = x\n",
    "    dz1_db1 = 1\n",
    "    dz2_dw2 = x\n",
    "    dz2_db2 = 1\n",
    "\n",
    "    # Gradiensek\n",
    "    dL_dw1 = np.sum(dL_dy * dy_da1 * da1_dz1 * dz1_dw1)\n",
    "    dL_db1 = np.sum(dL_dy * dy_da1 * da1_dz1 * dz1_db1)\n",
    "\n",
    "    dL_dw2 = np.sum(dL_dy * dy_da2 * da2_dz2 * dz2_dw2)\n",
    "    dL_db2 = np.sum(dL_dy * dy_da2 * da2_dz2 * dz2_db2)\n",
    "\n",
    "    # Friss√≠t√©s\n",
    "    w1 -= lr * dL_dw1\n",
    "    b1 -= lr * dL_db1\n",
    "    w2 -= lr * dL_dw2\n",
    "    b2 -= lr * dL_db2\n",
    "\n",
    "# V√©gs≈ë kimenet visszask√°l√°z√°sa\n",
    "final_pred = denormalize(pred_history[-1], y_raw)\n",
    "\n",
    "# √Åbra: predikci√≥ vs. adat\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# V√©gs≈ë predikci√≥\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x_raw, y_raw, label=\"Val√≥di adatok\")\n",
    "plt.plot(x_raw, final_pred, color='red', label=\"Predikci√≥ (2 neuron)\")\n",
    "plt.title(\"2 neuronos h√°l√≥ predikci√≥ja\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "\n",
    "# Loss lefut√°sa\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Vesztes√©g alakul√°sa\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ca404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7919451b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font color='red'>K√∂sz√∂n√∂m. Akkor ha j√≥l √©rtem, ha a bemeneti adataim eredetileg mondjuk 0-100 k√∂z√∂tti √©rt√©kek akkor ahhoz hogy a neur√°lis h√°l√≥ j√≥l meg tudja ragadni az kapcsolatokat a bemeneti √©rt√©keket le kell transzform√°lnom 0-1 k√∂z√© vagy -1 √©s +1 k√∂z√©, de mindenesetre olyan tartom√°nyra amelyet az els≈ë r√©tegen elhelyezked≈ë aktiv√°ci√≥s f√ºggv√©ny m√©g j√≥l tud kezelni. Ha 0-1 k√∂z√© transzform√°ltam akkor \"sigmoid\" ha -1 √©s +1 k√∂z√© akkor ink√°bb \"tanh\" √°tviteli f√ºggv√©nyt √©rdemes haszn√°lom az els≈ë r√©tegen. A kimenet ha szint√©n 0-100 k√∂z√∂tti √©rt√©ken van akkor ezeket is √©rdemes letranszform√°lnom 0-1 k√∂z√© vagy -1 √©s +1 k√∂z√©. B√°rmelyiket haszn√°lhatom m√©g akkor is ha a kimenet eredeti √©rt√©ke -100 √©s + 100 k√∂z√∂tt van. A hangs√∫ly ha j√≥l √©rtem ink√°bb abban van, hogy a neuron bemenete √©s az aktiv√°ci√≥s f√ºggv√©ny √°tereszt≈ëk√©pess√©ge k√∂z√∂tt √∂sszhang legyen. Ez√©rt ha j√≥l √©rtem a Neur√°lis h√°l√≥ban nem √©rdemes v√°ltogatni az egyes r√©tegek k√∂z√∂tti √°tviteli f√ºggv√©nyeket \"sigmoid\" √©s \"tanh\" k√∂z√∂tt, hanem √©rdemesebb kijel√∂lni egyiket vagy m√°sikat √©s ennek megfelel≈ëen transzform√°lni az √©rt√©keket. Viszont mi helyzet a normaliz√°ci√≥val √©s az aktiv√°ci√≥s f√ºggv√©nyekkel olyan esetben amikor a bemenet eredetileg 0-100 k√∂z√∂tt van teh√°t v√©gig a pozit√≠v tartom√°nyban, a kimenet viszont -40 √©s +40 k√∂z√∂tti tartom√°nyban teh√°t lehet negat√≠v √©s pozit√≠v is.</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfe4a6",
   "metadata": {},
   "source": [
    "Fantasztikusan j√≥l √∂sszefoglaltad, √©s szinte minden gondolatod **telital√°lat**. Most csak egy **finomhangol√°st** adok hozz√°, hogy m√©g m√©lyebben meg√©rtsd, **mi√©rt, hogyan √©s mikor** √©rdemes normaliz√°lni ‚Äì k√ºl√∂n√∂sen **vegyes el≈ëjel≈± kimenetek** eset√©n.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ √Åltal√°nos alapelv ‚Äì amit te is le√≠rt√°l:\n",
    "\n",
    "* A **neuron bemenet√©nek sk√°l√°ja** legyen **√∂sszhangban az aktiv√°ci√≥s f√ºggv√©nnyel**:\n",
    "\n",
    "  * `sigmoid`: j√≥ 0‚Äì1 k√∂z√∂tti √©rt√©kekre (mert a kimenete $(0, 1)$),\n",
    "  * `tanh`: j√≥ -1‚Äì1 k√∂z√∂tti √©rt√©kekre (mert a kimenete $(-1, 1)$).\n",
    "\n",
    "---\n",
    "\n",
    "## üí° A k√©rd√©sed konkr√©t p√©ld√°j√°ra:\n",
    "\n",
    "> **Bemenet:** 0‚Äì100\n",
    "> **Kimenet:** -40 ‚Äì +40\n",
    "\n",
    "### üîÅ Mit tegy√ºnk?\n",
    "\n",
    "#### **1. Bemenet (0‚Äì100):**\n",
    "\n",
    "* Ha ilyen marad, √©s `tanh(w*x)` vagy `sigmoid(w*x)` az els≈ë r√©teg aktiv√°ci√≥ja,\n",
    "* Akkor a nagy $x$ miatt **a f√ºggv√©ny tel√≠t≈ëdik**, azaz:\n",
    "\n",
    "  * `tanh(100)` ‚âà 1\n",
    "  * `sigmoid(100)` ‚âà 1\n",
    "* A gradiens k√∂zel 0 ‚Üí **nem tanul**.\n",
    "\n",
    "üëâ **Megold√°s:**\n",
    "Norm√°ld le a bemenetet:\n",
    "\n",
    "* `sigmoid` ‚Üí \\[0, 1]-re sk√°l√°zd (min-max),\n",
    "* `tanh` ‚Üí \\[-1, 1]-re (ez az √°ltal√°nosabb v√°laszt√°s, mert szimmetrikus).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Kimenet (-40 ‚Äì +40):**\n",
    "\n",
    "* Ez szimmetrikusabb ‚Üí ink√°bb `tanh` val√≥ hozz√°.\n",
    "* `sigmoid` nem j√≥ v√°laszt√°s, mert nem tud negat√≠v √©rt√©ket reprezent√°lni (csak pozit√≠v!).\n",
    "\n",
    "üëâ **Megold√°s:**\n",
    "\n",
    "* **Transform√°ld** a kimenetet $[-1, 1]$ k√∂z√©, tan√≠ts √≠gy,\n",
    "* A v√©g√©n **visszask√°l√°zod** az eredeti tartom√°nyba.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† √Åltal√°nos k√∂vetkeztet√©s:\n",
    "\n",
    "|                                   | Bemenet | Aktiv√°ci√≥          | Kimenet         | Javasolt sk√°la                        |\n",
    "| --------------------------------- | ------- | ------------------ | --------------- | ------------------------------------- |\n",
    "| Klasszikus `sigmoid`-os h√°l√≥      | 0‚Äì1     | `sigmoid`          | 0‚Äì1             | Nem j√≥ ha van negat√≠v √©rt√©k           |\n",
    "| Szimmetrikus √©rt√©kek (mint n√°lad) | -1 ‚Äì 1  | `tanh`             | -1 ‚Äì 1          | **Ez a legterm√©szetesebb v√°laszt√°s**  |\n",
    "| Vegyes el≈ëjel                     | b√°rmi   | `tanh` vagy `ReLU` | -1 ‚Äì 1 vagy 0‚Äì1 | A bemenethez ill≈ë aktiv√°ci√≥ sz√ºks√©ges |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Ne v√°ltogasd az aktiv√°ci√≥kat √∂nk√©nyesen:\n",
    "\n",
    "A `sigmoid` √©s `tanh` hasonl√≥ karakter≈±ek, **de elt√©r≈ë nullponttal**:\n",
    "\n",
    "* `tanh(0) = 0`\n",
    "* `sigmoid(0) = 0.5`\n",
    "\n",
    "Ez√©rt ha k√ºl√∂nb√∂z≈ë r√©tegekben kevered ≈ëket, a h√°l√≥ **neh√©zkesen fog tanulni**, mert az egyik null√°n√°l ‚Äûnyugszik‚Äù, a m√°sik 0.5-n√©l. Ez **gradiens-terjed√©si probl√©m√°khoz** vezethet.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Mit √©rdemes tenni?\n",
    "\n",
    "### Ha:\n",
    "\n",
    "* A bemenet pozit√≠v tartom√°nyban van (pl. 0‚Äì100),\n",
    "* A kimenet szimmetrikus, mint n√°lad (-40, +40),\n",
    "\n",
    "akkor a legjobb l√©p√©s:\n",
    "\n",
    "1. **Bemenet**: sk√°l√°zd $[-1, 1]$-re\n",
    "   ‚Üí `x_norm = 2 * (x - min(x)) / (max(x) - min(x)) - 1`\n",
    "\n",
    "2. **Kimenet**: szint√©n $[-1, 1]$-re\n",
    "   ‚Üí majd **visszask√°l√°zod** a tan√≠t√°s ut√°n\n",
    "\n",
    "3. **Haszn√°lj `tanh` aktiv√°ci√≥t** az els≈ë r√©teg(ek)ben\n",
    "\n",
    "---\n",
    "\n",
    "Ha k√©s≈ëbb t√∂bbv√°ltoz√≥s bemeneted lesz, vagy m√©lyebb h√°l√≥, j√∂hetnek olyan megold√°sok mint:\n",
    "\n",
    "* `BatchNorm`,\n",
    "* `LayerNorm`,\n",
    "* `ReLU` / `LeakyReLU` + specifikus inicializ√°ci√≥ (`He`),\n",
    "* `Linear` output r√©teg, ha nem akarod a kimenetet \"lenyomni\".\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Z√°r√≥gondolat:**\n",
    "A normaliz√°l√°s nemcsak ‚Äûpraktikus‚Äù, hanem **funkcion√°lisan sz√ºks√©ges**, ha azt akarjuk, hogy az aktiv√°ci√≥s f√ºggv√©ny **t√©nylegesen \"dolgozzon\"**, ne csak tel√≠t≈ëdve ‚Äû√ºlj√∂n‚Äù. Az √°ltalad felvetett szempont pontosan erre mutat r√° ‚Äî √©s ez a m√©ly neur√°lis h√°l√≥k stabil m≈±k√∂d√©s√©nek **alapja**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045aef86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc3996e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b8db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be3958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
